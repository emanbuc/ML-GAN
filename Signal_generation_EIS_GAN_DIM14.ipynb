{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Signal_generation_GAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNPUaUue9zsCCjcnpumuQfu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emanbuc/ML-GAN/blob/main/Signal_generation_EIS_GAN_DIM14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generative Adversarial Network - (GAN) \n",
        "\n",
        "> “Generative Adversarial Network— the most interesting idea in the last ten years in machine learning” by Yann LeCun, VP & Chief AI Scientist at Facebook, Godfather of AI.\n",
        "\n",
        "Generative Adversarial Network (GAN) is an old idea arising from the game theory, they were introduced to the machine learning community in 2014 by Ian J. Goodfellow and co-authors in the article Generative Adversarial Nets.\n",
        "\n",
        "\n",
        "Generative adversarial networks (GANs) are an exciting recent innovation in machine learning. GANs are generative models: they create new data instances that resemble your training data. For example, GANs can create images that look like photographs of human faces, even though the faces don't belong to any real person.\n",
        "\n",
        "![Images generated by a GAN created by NVIDIA](https://developers.google.com/machine-learning/gan/images/gan_faces.png)\n",
        "Figure 1: [Images generated by a GAN created by NVIDIA.](https://research.nvidia.com/sites/default/files/pubs/2017-10_Progressive-Growing-of/karras2018iclr-paper.pdf)\n"
      ],
      "metadata": {
        "id": "pFlMJF1js6jf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generative Model\n",
        "\n",
        "\"Generative\" describes a class of statistical models that contrasts with discriminative models.\n",
        "\n",
        "Informally:\n",
        "\n",
        "\n",
        "*   Generative models can generate new data \n",
        "\n",
        "*  Discriminative models discriminate between different kinds of data instances\n",
        "\n",
        "A generative model could generate new photos of animals that look like real animals, while a discriminative model could tell a dog from a cat. GANs are just one kind of generative model.\n",
        "\n",
        "More formally, given a set of data instances X and a set of labels Y:\n",
        "\n",
        "Generative models capture the joint probability p(X, Y), or just p(X) if there are no labels.\n",
        "Discriminative models capture the conditional probability p(Y | X).\n",
        "\n",
        "\n",
        "A generative model includes the distribution of the data itself, and tells you how likely a given example is. For example, models that predict the next word in a sequence are typically generative models (usually much simpler than GANs) because they can assign a probability to a sequence of words.\n",
        "\n",
        "A discriminative model ignores the question of whether a given instance is likely, and just tells you how likely a label is to apply to the instance.\n",
        "\n",
        "Note that this is a very general definition. There are many kinds of generative model. GANs are just one kind of generative model.\n",
        "\n"
      ],
      "metadata": {
        "id": "WEjAgvyLxpmP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Game of Probabilities \n",
        "From [Generative Adversarial Network (GAN) for Dummies — A Step By Step Tutorial](https://towardsdatascience.com/generative-adversarial-network-gan-for-dummies-a-step-by-step-tutorial-fdefff170391)"
      ],
      "metadata": {
        "id": "Rr_ToI1otYEQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating new data is a game of probabilities. When we are observing the world around us and collecting data, we are performing an experiment. A simple example is taking a photo of a celebrity's face.\n",
        "\n",
        "This can be considered as a probabilistic experiment, with an unknown outcome X, also called a random variable."
      ],
      "metadata": {
        "id": "CecQ4H-ttyW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For example, we can define the probability that the face will be that of Tyrese, the famous celebrity singer.\n",
        "\n",
        "![](https://miro.medium.com/max/141/1*idI7l3JkxRXxoI8xiqLzlA.png)\n",
        "\n",
        "Tyrese Gibson\n",
        "All possible outcomes of such experiments build the so-called sample space, denoted Ω (all possible celebrity faces) \n",
        "\n",
        "\n",
        "![https://miro.medium.com/max/399/0*9_sm2wxAUGclWjEA.png](https://miro.medium.com/max/399/0*9_sm2wxAUGclWjEA.png)"
      ],
      "metadata": {
        "id": "IobtZjnOt3sk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore we can consider probability as a function that takes an outcome, i.e. an element from the sample space (a photo) and maps the outcome to a non-negative real number so that the sum of all these numbers equals 1.\n",
        "\n",
        "We also call this a probability distribution function P(X). When we know the sample space (all possible celebrity faces) and the probability distribution (the probability of occurrence of each face), we have the full description of the experiment and we can reason about uncertainty.\n",
        "\n",
        "Generating new faces can be expressed by a random variable generation problem. The face is described by random variables, represented through its RGB values, flatten into a vector of N numbers.\n",
        "The celebrity faces are 218px height, 178px width with 3 color channels. Therefore each vector is 116412-dimensional.\n",
        "If we build a space with 116412 (N) axes, each face will be a point in that space. A celebrity-face probability distribution function P(X) would map each face to a non-negative real number so that the sum of all these numbers for all faces equals 1.\n",
        "\n",
        "Some points of that space are very likely to represent celebrity faces whereas it is highly unlikely for some others.\n",
        "\n",
        "![](https://miro.medium.com/max/645/1*XLCCQeGArsYHrcd9CJWkSg.png)\n"
      ],
      "metadata": {
        "id": "9rLHB7cLu-1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to generate random variables from complex distributions?\n",
        "\n",
        "The celebrity-face probability distribution over the N-dimensional vector space is a very complex one and we don’t know how to directly generate complex random variables.\n",
        "\n",
        "Luckily, we can represent our complex random variable by a function applied to a uniform random variable. This is the idea of the transform method. It first generates N uncorrelated uniform random variables, which is easy. It then applies a very complex function to that simple random variable! Very complex functions are naturally approximated by a neural network. After training the network will be able to take as input a simple N-dimensional uniform random variable and return another N-dimensional random variable that would follow our celebrity-face probability distribution. This is the core motivation behind generative adversarial networks.\n",
        "\n",
        "> In simple words, a GAN would generate a random variable with respect to a specific probability distribution.\n",
        "\n",
        "### Why Generative Adversarial Networks?\n",
        "\n",
        "Theoretically, we would compare the true distribution versus the generated distribution based on samples using the Maximum Mean Discrepancy (MMD) approach.\n",
        "\n",
        "This would give a distribution matching error that could be used to update the network via backpropagation. This direct method is practically very complex to implement.\n",
        "\n",
        "> Instead of directly comparing both true and generated distributions, GANs solve a non-discrimination task between true and generated samples"
      ],
      "metadata": {
        "id": "W7HddQa_vgx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generative Models are HArd\n",
        "\n",
        "From : [generative-models-are-hard](https://developers.google.com/machine-learning/gan/generative#generative-models-are-hard)\n",
        "\n",
        "\n",
        "Generative models tackle a more difficult task than analogous discriminative models. Generative models have to model more.\n",
        "\n",
        "A generative model for images might capture correlations like \"things that look like boats are probably going to appear near things that look like water\" and \"eyes are unlikely to appear on foreheads.\" These are very complicated distributions.\n",
        "\n",
        "In contrast, a discriminative model might learn the difference between \"sailboat\" or \"not sailboat\" by just looking for a few tell-tale patterns. It could ignore many of the correlations that the generative model must get right.\n",
        "\n",
        "Discriminative models try to draw boundaries in the data space, while generative models try to model how data is placed throughout the space. For example, the following diagram shows discriminative and generative models of handwritten digits:\n",
        "\n",
        "![](https://developers.google.com/machine-learning/gan/images/generative_v_discriminative.png)\n",
        "\n",
        "The discriminative model tries to tell the difference between handwritten 0's and 1's by drawing a line in the data space. If it gets the line right, it can distinguish 0's from 1's without ever having to model exactly where the instances are placed in the data space on either side of the line.\n",
        "\n",
        "In contrast, the generative model tries to produce convincing 1's and 0's by generating digits that fall close to their real counterparts in the data space. It has to model the distribution throughout the data space.\n",
        "\n",
        "GANs offer an effective way to train such rich models to resemble a real distribution. To understand how they work we'll need to understand the basic structure of a GAN."
      ],
      "metadata": {
        "id": "4tg-hk7dzD-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A generative adversarial network (GAN) has two parts:\n",
        "\n",
        "- The generator learns to generate plausible data. The generated instances become negative training examples for the discriminator.\n",
        "- The discriminator learns to distinguish the generator's fake data from real data. The discriminator penalizes the generator for producing implausible results.\n",
        "\n",
        "![](https://developers.google.com/machine-learning/gan/images/gan_diagram.svg)\n",
        "\n",
        "Both the generator and the discriminator are neural networks. The generator output is connected directly to the discriminator input. Through backpropagation, the discriminator's classification provides a signal that the generator uses to update its weights.\n",
        "\n",
        "Let's explain the pieces of this system in greater detail."
      ],
      "metadata": {
        "id": "w6K65IiRz_sD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Discriminator\n",
        "\n",
        "The discriminator in a GAN is simply a classifier. It tries to distinguish real data from the data created by the generator. It could use any network architecture appropriate to the type of data it's classifying.\n",
        "\n",
        "The discriminator's training data comes from two sources:\n",
        "\n",
        "- Real data instances, such as real pictures of people. The discriminator uses these instances as positive examples during training.\n",
        "- Fake data instances created by the generator. The discriminator uses these instances as negative examples during training.-\n",
        "\n"
      ],
      "metadata": {
        "id": "e1Ldyywq0fKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAN Architecture\n",
        "\n",
        "A GAN has three primary components: a generator model for generating new data, a discriminator model for classifying whether generated data are real faces, or fake, and the adversarial network that pits them against each other.\n",
        "\n",
        "The generative part is responsible for taking N-dimensional uniform random variables (noise) as input and generating fake faces. The generator captures the probability P(X), where X is the input.\n",
        "The discriminative part is a simple classifier that evaluates and distinguished the generated faces from true celebrity faces. The discriminator captures the conditional probability P(Y|X), where X is the input and Y is the label."
      ],
      "metadata": {
        "id": "Va7phJWdwJaM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Generative Adversarial Networks\n",
        "\n",
        "The generative network is trained to maximize the final classification error (between true and generated data), while the discriminative network is trained to minimize it. This is where the notion of adversarial networks arises from.\n",
        "From the perspective of game theory, equilibrium is reached when the generator produces samples that follow the celebrity-face probability distribution and the discriminator predicts fake or not-fake with equal probability as if it would just flip a coin.\n",
        "It is important that both networks learn equally during training and converge together. A typical situation occurs when the discriminative network becomes much better at recognizing fakes, causing the generative network to be stuck.\n",
        "\n",
        "During discriminator training, we ignore the generator loss and just use the discriminator loss, which penalizes the discriminator for misclassifying real faces as fake or generated faces as real. The generator’s weights are updated through backpropagation. Generator’s weights are not updated.\n",
        "During generator training, we use the generator loss, which penalizes the generator for failing to fool the discriminator and generating a face that the discriminator classifies as fake. The discriminator is frozen during generator training and only generator’s weights are updated through backpropagation.\n",
        "This is the magic that synthesizes celebrity faces using GANs. Convergence is often observed as fleeting, rather than stable. When you get everything right, GANs provide unbelievable results as demonstrated below.\n"
      ],
      "metadata": {
        "id": "Rn4qRafvwWdJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "p804XzJIttgD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MyfpDCIQiGNk"
      },
      "outputs": [],
      "source": [
        "!pip install fastai==2.5.3 -q\n",
        "import torch\n",
        "from torch import nn\n",
        "import sys\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#It’s a good practice to set up a random generator seed so that the experiment can be replicated identically on any machine. \n",
        "#To do that in PyTorch:\n",
        "torch.manual_seed(123)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PF1YmfGiN8L",
        "outputId": "03437d47-37fe-4700-9754-536698ea8a0a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f408f0292b0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2D Sinusoidal signal generator GAN"
      ],
      "metadata": {
        "id": "E53BbwF2ngLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing the Discriminator\n",
        "\n",
        "In PyTorch, the neural network models are represented by classes that inherit from nn.Module.\n",
        "\n",
        "The discriminator is a model with a two-dimensional input and a one-dimensional output. It’ll receive a sample from the real data or from the generator and will provide the probability that the sample belongs to the real training data.\n",
        "\n",
        "To build the model. First, you need to call super().__init__() to run .__init__() from nn.Module. Then the model id defined in a sequential way using nn.Sequential()"
      ],
      "metadata": {
        "id": "YAi3rv1UlTod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This discriminator is an MLP neural network \n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            #The input is two-dimensional, and the first hidden layer is composed \n",
        "            # of 256 neurons with ReLU activation.\n",
        "            nn.Linear(3, 256),\n",
        "            nn.ReLU(),\n",
        "            # use dropout after hidden layer to avoid overfitting.\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 1),\n",
        "            # The output is composed of a single neuron with sigmoidal activation\n",
        "            # to represent a probability.\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "     # .forward() to describe how the output of the model is calculated\n",
        "    def forward(self, x):\n",
        "        output = self.model(x)\n",
        "        return output\n",
        "\n",
        "# instantiate a Discriminator object\n",
        "discriminator = Discriminator()"
      ],
      "metadata": {
        "id": "72rB6fQGlTDt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generator\n",
        "\n",
        "In generative adversarial networks, the generator is the model that takes samples from a latent space as its input and generates data resembling the data in the training set. In this case, it’s a model with a two-dimensional input, which will receive random points (z₁, z₂), and a two-dimensional output that must provide (x̃₁, x̃₂) points resembling those from the training data.\n",
        "\n"
      ],
      "metadata": {
        "id": "KRcqwZflntcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(3, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 3),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.model(x)\n",
        "        return output\n",
        "\n",
        "generator = Generator()"
      ],
      "metadata": {
        "id": "kD10TWE3npkj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This way, the output will consist of a vector with two elements that can be any value ranging from negative infinity to infinity, which will represent (x̃₁, x̃₂)."
      ],
      "metadata": {
        "id": "qJwQdBpooHZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the Training Data Sin(x)\n",
        "The training data is composed of pairs (x₁, x₂) so that x₂ consists of the value of the sine of x₁ for x₁ in the interval from 0 to 2π"
      ],
      "metadata": {
        "id": "QoYhq9F-i1cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load EB_ML python libraries\n",
        "# The following libraries are used in this notebook and should be installed in your local machine before running this notebook.\n",
        "# eb_colab_utils.py\n",
        "# eb_ml_battery_lib.py\n",
        "# eb_ml_utils.py\n",
        "\n",
        "# path to load external *.py files used in this notebook\n",
        "# Note: in Google Colab virtual machine you shoud copy the files in \"/content\" folder after BEFORE running this notebook's cell\n",
        "external_python_file_path=\"'/.'\"\n",
        "sys.path.append(external_python_file_path)\n",
        "\n",
        "\n",
        "from eb_ml_colab_utils import get_root_path,copy_model_to_google_drive\n",
        "from eb_ml_battery_lib import load_soc_dataset,generate_image_files_from_eis\n",
        "from eb_ml_utils import save_model_weights,build_data_loader,build_and_train_learner,score_model"
      ],
      "metadata": {
        "id": "4jJ1ntopcziK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#configuration dictionary\n",
        "config ={}\n",
        "\n",
        "# Root working folder (local or Google Drive)\n",
        "# config['ROOT_DIR'] = get_root_path(\"batterie\")\n",
        "config['ROOT_DIR'] = get_root_path(\"batterie\")  \n",
        "\n",
        "# Folder with dataset in CSV format\n",
        "#config['DATASETS_DIR'] = config['ROOT_DIR']+\"/datasets\"\n",
        "config['DATASETS_DIR'] = config['ROOT_DIR']+\"/datasets/EIS-vs-SOC-2022\"\n",
        "\n",
        "# List of SoC level into dataset\n",
        "#config['soc_list']=['100','090','080','070','060','050','040','030','020','010']\n",
        "config['soc_list']=['100','090','080','070','060','050','040','030','020','010']\n",
        "\n",
        "\n",
        "# Folder to store trained model\n",
        "#config['MODELS_DIR'] = config['ROOT_DIR']+\"/models\"\n",
        "config['MODELS_DIR'] = config['ROOT_DIR']+\"/models\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd5lis1Ec6HW",
        "outputId": "0c077955-30b3-402a-aa75-4bba9ac9ce94"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on COLAB\n",
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data acquition file to load from dateset folder\n",
        "# EIS Dataset https://data.mendeley.com/datasets/ch3sydbbrg/2\n",
        "frequency_list=[ 0.05, 0.1, 0.2, 0.4, 1, 2, 4, 10, 20, 40, 100, 200, 400, 1000]\n",
        "battery_list=[1,2,3,4,5,7,8,9,10,11,12,13]\n",
        "dataset,feature_col_names=load_soc_dataset(battery_list,config[\"soc_list\"],config['DATASETS_DIR'])"
      ],
      "metadata": {
        "id": "zAWvQQ-mc85P"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soc_10_training=dataset.query('SOC== \"010\"')[feature_col_names]\n",
        "soc_10_training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "IzqxlXYTc_00",
        "outputId": "f6669f58-36e5-4236-9e82-9d579bd01f3f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Z_f0                Z_f1                Z_f2  \\\n",
              "010  0.079771-0.005349j  0.077740-0.004683j  0.076173-0.003523j   \n",
              "010  0.078894-0.004942j  0.077379-0.003965j  0.076076-0.003162j   \n",
              "010  0.074923-0.004870j  0.073477-0.003759j  0.072532-0.002710j   \n",
              "010  0.074411-0.004880j  0.072787-0.003883j  0.071541-0.003067j   \n",
              "010  0.078197-0.004944j  0.076708-0.003921j  0.075516-0.002831j   \n",
              "010  0.073499-0.004352j  0.071975-0.003375j  0.071127-0.002276j   \n",
              "010  0.075002-0.004450j  0.073594-0.003316j  0.072728-0.002386j   \n",
              "010  0.079897-0.004582j  0.078391-0.003490j  0.077319-0.002565j   \n",
              "010  0.077036-0.004560j  0.075534-0.003552j  0.074379-0.002565j   \n",
              "010  0.097612-0.004647j  0.095967-0.003856j  0.094797-0.002671j   \n",
              "010  0.071875-0.003984j  0.070516-0.003260j  0.069583-0.002225j   \n",
              "010  0.074011-0.004292j  0.072539-0.003420j  0.071548-0.002388j   \n",
              "\n",
              "                   Z_f3                Z_f4                Z_f5  \\\n",
              "010  0.075399-0.003229j  0.073304-0.003548j  0.071919-0.004337j   \n",
              "010  0.075439-0.002577j  0.073901-0.002919j  0.072642-0.003744j   \n",
              "010  0.071758-0.002316j  0.070510-0.002377j  0.069565-0.003037j   \n",
              "010  0.070933-0.002429j  0.069589-0.002628j  0.068560-0.003292j   \n",
              "010  0.074972-0.002334j  0.073589-0.002613j  0.072889-0.003227j   \n",
              "010  0.070579-0.001976j  0.069628-0.001913j  0.069061-0.002316j   \n",
              "010  0.072421-0.002074j  0.071293-0.002048j  0.070492-0.002500j   \n",
              "010  0.076870-0.001969j  0.075815-0.002046j  0.075152-0.002592j   \n",
              "010  0.073773-0.002133j  0.072797-0.002270j  0.072098-0.002704j   \n",
              "010  0.094201-0.002246j  0.093193-0.002260j  0.092317-0.002724j   \n",
              "010  0.069102-0.001781j  0.068355-0.001730j  0.067728-0.002101j   \n",
              "010  0.071018-0.001970j  0.070191-0.001974j  0.069458-0.002370j   \n",
              "\n",
              "                   Z_f6                Z_f7                Z_f8  \\\n",
              "010  0.069978-0.004903j  0.066565-0.005511j  0.063821-0.005493j   \n",
              "010  0.070944-0.004596j  0.067612-0.005322j  0.064984-0.005585j   \n",
              "010  0.068364-0.003993j  0.065447-0.005366j  0.062517-0.006183j   \n",
              "010  0.067239-0.003997j  0.064362-0.005227j  0.061435-0.005945j   \n",
              "010  0.071461-0.004222j  0.068578-0.005554j  0.065428-0.006255j   \n",
              "010  0.068349-0.002973j  0.066075-0.004737j  0.063371-0.005850j   \n",
              "010  0.069626-0.003237j  0.067319-0.004893j  0.064682-0.005829j   \n",
              "010  0.074303-0.003259j  0.071812-0.004872j  0.069079-0.005790j   \n",
              "010  0.071250-0.003512j  0.068566-0.005268j  0.065698-0.006345j   \n",
              "010  0.091361-0.003504j  0.088793-0.004872j  0.086085-0.005751j   \n",
              "010  0.066984-0.002790j  0.065122-0.004238j  0.062783-0.005229j   \n",
              "010  0.068559-0.003093j  0.066522-0.004606j  0.063936-0.005608j   \n",
              "\n",
              "                   Z_f9               Z_f10               Z_f11  \\\n",
              "010  0.061411-0.005366j  0.057958-0.005174j  0.055633-0.004818j   \n",
              "010  0.062448-0.005382j  0.059086-0.005205j  0.056763-0.004722j   \n",
              "010  0.059429-0.006285j  0.055555-0.005599j  0.053129-0.004991j   \n",
              "010  0.058558-0.005913j  0.054922-0.005389j  0.052485-0.004896j   \n",
              "010  0.062342-0.006436j  0.058299-0.005866j  0.055709-0.005264j   \n",
              "010  0.060204-0.006134j  0.056277-0.005871j  0.053678-0.004992j   \n",
              "010  0.061710-0.006009j  0.057768-0.005385j  0.055370-0.004826j   \n",
              "010  0.065966-0.006023j  0.062122-0.005708j  0.059560-0.004794j   \n",
              "010  0.062095-0.006770j  0.057652-0.006236j  0.054922-0.005423j   \n",
              "010  0.083177-0.006003j  0.079377-0.005685j  0.076842-0.005000j   \n",
              "010  0.059880-0.005821j  0.056042-0.005589j  0.053541-0.004915j   \n",
              "010  0.060867-0.006227j  0.056886-0.005825j  0.054247-0.005141j   \n",
              "\n",
              "                  Z_f12               Z_f13  \n",
              "010  0.053745-0.004118j  0.051447-0.003001j  \n",
              "010  0.054563-0.004204j  0.052500-0.002999j  \n",
              "010  0.050902-0.004287j  0.048653-0.003007j  \n",
              "010  0.050414-0.004192j  0.048036-0.003069j  \n",
              "010  0.053496-0.004382j  0.051192-0.003051j  \n",
              "010  0.051553-0.004286j  0.049336-0.002925j  \n",
              "010  0.053423-0.003888j  0.051324-0.002779j  \n",
              "010  0.057592-0.003948j  0.055631-0.002843j  \n",
              "010  0.052739-0.004440j  0.050409-0.003261j  \n",
              "010  0.074681-0.004194j  0.072418-0.002935j  \n",
              "010  0.051409-0.004200j  0.049157-0.002987j  \n",
              "010  0.052139-0.004326j  0.049798-0.003033j  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b223142-1ad0-4d0d-8e39-538be77c283a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Z_f0</th>\n",
              "      <th>Z_f1</th>\n",
              "      <th>Z_f2</th>\n",
              "      <th>Z_f3</th>\n",
              "      <th>Z_f4</th>\n",
              "      <th>Z_f5</th>\n",
              "      <th>Z_f6</th>\n",
              "      <th>Z_f7</th>\n",
              "      <th>Z_f8</th>\n",
              "      <th>Z_f9</th>\n",
              "      <th>Z_f10</th>\n",
              "      <th>Z_f11</th>\n",
              "      <th>Z_f12</th>\n",
              "      <th>Z_f13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>010</th>\n",
              "      <td>0.079771-0.005349j</td>\n",
              "      <td>0.077740-0.004683j</td>\n",
              "      <td>0.076173-0.003523j</td>\n",
              "      <td>0.075399-0.003229j</td>\n",
              "      <td>0.073304-0.003548j</td>\n",
              "      <td>0.071919-0.004337j</td>\n",
              "      <td>0.069978-0.004903j</td>\n",
              "      <td>0.066565-0.005511j</td>\n",
              "      <td>0.063821-0.005493j</td>\n",
              "      <td>0.061411-0.005366j</td>\n",
              "      <td>0.057958-0.005174j</td>\n",
              "      <td>0.055633-0.004818j</td>\n",
              "      <td>0.053745-0.004118j</td>\n",
              "      <td>0.051447-0.003001j</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>010</th>\n",
              "      <td>0.078894-0.004942j</td>\n",
              "      <td>0.077379-0.003965j</td>\n",
              "      <td>0.076076-0.003162j</td>\n",
              "      <td>0.075439-0.002577j</td>\n",
              "      <td>0.073901-0.002919j</td>\n",
              "      <td>0.072642-0.003744j</td>\n",
              "      <td>0.070944-0.004596j</td>\n",
              "      <td>0.067612-0.005322j</td>\n",
              "      <td>0.064984-0.005585j</td>\n",
              "      <td>0.062448-0.005382j</td>\n",
              "      <td>0.059086-0.005205j</td>\n",
              "      <td>0.056763-0.004722j</td>\n",
              "      <td>0.054563-0.004204j</td>\n",
              "      <td>0.052500-0.002999j</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>010</th>\n",
              "      <td>0.074923-0.004870j</td>\n",
              "      <td>0.073477-0.003759j</td>\n",
              "      <td>0.072532-0.002710j</td>\n",
              "      <td>0.071758-0.002316j</td>\n",
              "      <td>0.070510-0.002377j</td>\n",
              "      <td>0.069565-0.003037j</td>\n",
              "      <td>0.068364-0.003993j</td>\n",
              "      <td>0.065447-0.005366j</td>\n",
              "      <td>0.062517-0.006183j</td>\n",
              "      <td>0.059429-0.006285j</td>\n",
              "      <td>0.055555-0.005599j</td>\n",
              "      <td>0.053129-0.004991j</td>\n",
              "      <td>0.050902-0.004287j</td>\n",
              "      <td>0.048653-0.003007j</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>010</th>\n",
              "      <td>0.074411-0.004880j</td>\n",
              "      <td>0.072787-0.003883j</td>\n",
              "      <td>0.071541-0.003067j</td>\n",
              "      <td>0.070933-0.002429j</td>\n",
              "      <td>0.069589-0.002628j</td>\n",
              "      <td>0.068560-0.003292j</td>\n",
              "      <td>0.067239-0.003997j</td>\n",
              "      <td>0.064362-0.005227j</td>\n",
              "      <td>0.061435-0.005945j</td>\n",
              "      <td>0.058558-0.005913j</td>\n",
              "      <td>0.054922-0.005389j</td>\n",
              "      <td>0.052485-0.004896j</td>\n",
              "      <td>0.050414-0.004192j</td>\n",
              "      <td>0.048036-0.003069j</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>010</th>\n",
              "      <td>0.078197-0.004944j</td>\n",
              "      <td>0.076708-0.003921j</td>\n",
              "      <td>0.075516-0.002831j</td>\n",
              "      <td>0.074972-0.002334j</td>\n",
              "      <td>0.073589-0.002613j</td>\n",
              "      <td>0.072889-0.003227j</td>\n",
              "      <td>0.071461-0.004222j</td>\n",
              "      <td>0.068578-0.005554j</td>\n",
              "      <td>0.065428-0.006255j</td>\n",
              "      <td>0.062342-0.006436j</td>\n",
              "      <td>0.058299-0.005866j</td>\n",
              "      <td>0.055709-0.005264j</td>\n",
              "      <td>0.053496-0.004382j</td>\n",
              "      <td>0.051192-0.003051j</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>010</th>\n",
              "      <td>0.073499-0.004352j</td>\n",
              "      <td>0.071975-0.003375j</td>\n",
              "      <td>0.071127-0.002276j</td>\n",
              "      <td>0.070579-0.001976j</td>\n",
              "      <td>0.069628-0.001913j</td>\n",
              "      <td>0.069061-0.002316j</td>\n",
              "      <td>0.068349-0.002973j</td>\n",
              "      <td>0.066075-0.004737j</td>\n",
              "      <td>0.063371-0.005850j</td>\n",
              "      <td>0.060204-0.006134j</td>\n",
              "      <td>0.056277-0.005871j</td>\n",
              "      <td>0.053678-0.004992j</td>\n",
              "      <td>0.051553-0.004286j</td>\n",
              "      <td>0.049336-0.002925j</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>010</th>\n",
              "      <td>0.075002-0.004450j</td>\n",
              "      <td>0.073594-0.003316j</td>\n",
              "      <td>0.072728-0.002386j</td>\n",
              "      <td>0.072421-0.002074j</td>\n",
              "      <td>0.071293-0.002048j</td>\n",
              "      <td>0.070492-0.002500j</td>\n",
              "      <td>0.069626-0.003237j</td>\n",
              "      <td>0.067319-0.004893j</td>\n",
              "      <td>0.064682-0.005829j</td>\n",
              "      <td>0.061710-0.006009j</td>\n",
              "      <td>0.057768-0.005385j</td>\n",
              "      <td>0.055370-0.004826j</td>\n",
              "      <td>0.053423-0.003888j</td>\n",
              "      <td>0.051324-0.002779j</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>010</th>\n",
              "      <td>0.079897-0.004582j</td>\n",
              "      <td>0.078391-0.003490j</td>\n",
              "      <td>0.077319-0.002565j</td>\n",
              "      <td>0.076870-0.001969j</td>\n",
              "      <td>0.075815-0.002046j</td>\n",
              "      <td>0.075152-0.002592j</td>\n",
              "      <td>0.074303-0.003259j</td>\n",
              "      <td>0.071812-0.004872j</td>\n",
              "      <td>0.069079-0.005790j</td>\n",
              "      <td>0.065966-0.006023j</td>\n",
              "      <td>0.062122-0.005708j</td>\n",
              "      <td>0.059560-0.004794j</td>\n",
              "      <td>0.057592-0.003948j</td>\n",
              "      <td>0.055631-0.002843j</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>010</th>\n",
              "      <td>0.077036-0.004560j</td>\n",
              "      <td>0.075534-0.003552j</td>\n",
              "      <td>0.074379-0.002565j</td>\n",
              "      <td>0.073773-0.002133j</td>\n",
              "      <td>0.072797-0.002270j</td>\n",
              "      <td>0.072098-0.002704j</td>\n",
              "      <td>0.071250-0.003512j</td>\n",
              "      <td>0.068566-0.005268j</td>\n",
              "      <td>0.065698-0.006345j</td>\n",
              "      <td>0.062095-0.006770j</td>\n",
              "      <td>0.057652-0.006236j</td>\n",
              "      <td>0.054922-0.005423j</td>\n",
              "      <td>0.052739-0.004440j</td>\n",
              "      <td>0.050409-0.003261j</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>010</th>\n",
              "      <td>0.097612-0.004647j</td>\n",
              "      <td>0.095967-0.003856j</td>\n",
              "      <td>0.094797-0.002671j</td>\n",
              "      <td>0.094201-0.002246j</td>\n",
              "      <td>0.093193-0.002260j</td>\n",
              "      <td>0.092317-0.002724j</td>\n",
              "      <td>0.091361-0.003504j</td>\n",
              "      <td>0.088793-0.004872j</td>\n",
              "      <td>0.086085-0.005751j</td>\n",
              "      <td>0.083177-0.006003j</td>\n",
              "      <td>0.079377-0.005685j</td>\n",
              "      <td>0.076842-0.005000j</td>\n",
              "      <td>0.074681-0.004194j</td>\n",
              "      <td>0.072418-0.002935j</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>010</th>\n",
              "      <td>0.071875-0.003984j</td>\n",
              "      <td>0.070516-0.003260j</td>\n",
              "      <td>0.069583-0.002225j</td>\n",
              "      <td>0.069102-0.001781j</td>\n",
              "      <td>0.068355-0.001730j</td>\n",
              "      <td>0.067728-0.002101j</td>\n",
              "      <td>0.066984-0.002790j</td>\n",
              "      <td>0.065122-0.004238j</td>\n",
              "      <td>0.062783-0.005229j</td>\n",
              "      <td>0.059880-0.005821j</td>\n",
              "      <td>0.056042-0.005589j</td>\n",
              "      <td>0.053541-0.004915j</td>\n",
              "      <td>0.051409-0.004200j</td>\n",
              "      <td>0.049157-0.002987j</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>010</th>\n",
              "      <td>0.074011-0.004292j</td>\n",
              "      <td>0.072539-0.003420j</td>\n",
              "      <td>0.071548-0.002388j</td>\n",
              "      <td>0.071018-0.001970j</td>\n",
              "      <td>0.070191-0.001974j</td>\n",
              "      <td>0.069458-0.002370j</td>\n",
              "      <td>0.068559-0.003093j</td>\n",
              "      <td>0.066522-0.004606j</td>\n",
              "      <td>0.063936-0.005608j</td>\n",
              "      <td>0.060867-0.006227j</td>\n",
              "      <td>0.056886-0.005825j</td>\n",
              "      <td>0.054247-0.005141j</td>\n",
              "      <td>0.052139-0.004326j</td>\n",
              "      <td>0.049798-0.003033j</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b223142-1ad0-4d0d-8e39-538be77c283a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b223142-1ad0-4d0d-8e39-538be77c283a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b223142-1ad0-4d0d-8e39-538be77c283a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_EIS_num = len(soc_10_training)\n",
        "n_frequency =len(frequency_list)\n",
        "train_data_length = total_EIS_num * n_frequency  #14*11\n",
        "\n",
        "# initialize train_data, a tensor with dimensions of <train_data_length> rows and 3 columns, all containing zeros. \n",
        "train_data = torch.zeros((train_data_length,3))"
      ],
      "metadata": {
        "id": "39qrEqlRdELE"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import mod\n",
        "from torch import functional\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "for i  in range(0,train_data_length):\n",
        "  f_index = i % 14\n",
        "  row_index = i // 14\n",
        "  # print(\"Row index \"+str(row_index)+\"f_\"+str(f_index))\n",
        "  # the first column of train_data store the frequency values\n",
        "  train_data[i, 0] = frequency_list[f_index]\n",
        "  # the second column of the tensor  ReZ(f) , tird column Img Z(f)\n",
        "  train_data[i, 1] = functional.Tensor(np.real(soc_10_training))[row_index,f_index]\n",
        "  train_data[i, 2] = functional.Tensor(np.imag(soc_10_training))[row_index,f_index]"
      ],
      "metadata": {
        "id": "pmk50033dSat"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# init tensor of labels, which are required by PyTorch’s data loader. \n",
        "# Since GANs make use of unsupervised learning techniques, the labels can be anything.\n",
        "train_labels = torch.zeros(train_data_length)\n",
        "\n",
        "# create train_set as a list of tuples, with each row of train_data and train_labels represented in each tuple \n",
        "# this is the format expected by PyTorch’s data loader.\n",
        "train_set = [\n",
        "    (train_data[i], train_labels[i]) for i in range(train_data_length)\n",
        "]"
      ],
      "metadata": {
        "id": "By7gUloSicB6"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88sT8gt5jEKQ",
        "outputId": "935ea245-f9b6-436d-a5fb-9b9ff574fd44"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(tensor([ 0.0500,  0.0798, -0.0053]), tensor(0.)),\n",
              " (tensor([ 0.1000,  0.0777, -0.0047]), tensor(0.)),\n",
              " (tensor([ 0.2000,  0.0762, -0.0035]), tensor(0.)),\n",
              " (tensor([ 0.4000,  0.0754, -0.0032]), tensor(0.)),\n",
              " (tensor([ 1.0000,  0.0733, -0.0035]), tensor(0.)),\n",
              " (tensor([ 2.0000,  0.0719, -0.0043]), tensor(0.)),\n",
              " (tensor([ 4.0000,  0.0700, -0.0049]), tensor(0.)),\n",
              " (tensor([ 1.0000e+01,  6.6565e-02, -5.5107e-03]), tensor(0.)),\n",
              " (tensor([ 2.0000e+01,  6.3821e-02, -5.4931e-03]), tensor(0.)),\n",
              " (tensor([ 4.0000e+01,  6.1411e-02, -5.3664e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+02,  5.7958e-02, -5.1744e-03]), tensor(0.)),\n",
              " (tensor([ 2.0000e+02,  5.5633e-02, -4.8185e-03]), tensor(0.)),\n",
              " (tensor([ 4.0000e+02,  5.3745e-02, -4.1176e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+03,  5.1447e-02, -3.0014e-03]), tensor(0.)),\n",
              " (tensor([ 0.0500,  0.0789, -0.0049]), tensor(0.)),\n",
              " (tensor([ 0.1000,  0.0774, -0.0040]), tensor(0.)),\n",
              " (tensor([ 0.2000,  0.0761, -0.0032]), tensor(0.)),\n",
              " (tensor([ 0.4000,  0.0754, -0.0026]), tensor(0.)),\n",
              " (tensor([ 1.0000,  0.0739, -0.0029]), tensor(0.)),\n",
              " (tensor([ 2.0000,  0.0726, -0.0037]), tensor(0.)),\n",
              " (tensor([ 4.0000,  0.0709, -0.0046]), tensor(0.)),\n",
              " (tensor([ 1.0000e+01,  6.7612e-02, -5.3216e-03]), tensor(0.)),\n",
              " (tensor([ 2.0000e+01,  6.4984e-02, -5.5853e-03]), tensor(0.)),\n",
              " (tensor([ 4.0000e+01,  6.2447e-02, -5.3815e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+02,  5.9086e-02, -5.2052e-03]), tensor(0.)),\n",
              " (tensor([ 2.0000e+02,  5.6763e-02, -4.7219e-03]), tensor(0.)),\n",
              " (tensor([ 4.0000e+02,  5.4563e-02, -4.2036e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+03,  5.2500e-02, -2.9987e-03]), tensor(0.)),\n",
              " (tensor([ 0.0500,  0.0749, -0.0049]), tensor(0.)),\n",
              " (tensor([ 0.1000,  0.0735, -0.0038]), tensor(0.)),\n",
              " (tensor([ 0.2000,  0.0725, -0.0027]), tensor(0.)),\n",
              " (tensor([ 0.4000,  0.0718, -0.0023]), tensor(0.)),\n",
              " (tensor([ 1.0000,  0.0705, -0.0024]), tensor(0.)),\n",
              " (tensor([ 2.0000,  0.0696, -0.0030]), tensor(0.)),\n",
              " (tensor([ 4.0000e+00,  6.8364e-02, -3.9929e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+01,  6.5447e-02, -5.3657e-03]), tensor(0.)),\n",
              " (tensor([ 2.0000e+01,  6.2517e-02, -6.1826e-03]), tensor(0.)),\n",
              " (tensor([ 4.0000e+01,  5.9429e-02, -6.2848e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+02,  5.5555e-02, -5.5986e-03]), tensor(0.)),\n",
              " (tensor([ 2.0000e+02,  5.3129e-02, -4.9912e-03]), tensor(0.)),\n",
              " (tensor([ 4.0000e+02,  5.0902e-02, -4.2868e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+03,  4.8653e-02, -3.0069e-03]), tensor(0.)),\n",
              " (tensor([ 0.0500,  0.0744, -0.0049]), tensor(0.)),\n",
              " (tensor([ 0.1000,  0.0728, -0.0039]), tensor(0.)),\n",
              " (tensor([ 0.2000,  0.0715, -0.0031]), tensor(0.)),\n",
              " (tensor([ 0.4000,  0.0709, -0.0024]), tensor(0.)),\n",
              " (tensor([ 1.0000,  0.0696, -0.0026]), tensor(0.)),\n",
              " (tensor([ 2.0000,  0.0686, -0.0033]), tensor(0.)),\n",
              " (tensor([ 4.0000e+00,  6.7239e-02, -3.9968e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+01,  6.4362e-02, -5.2267e-03]), tensor(0.)),\n",
              " (tensor([ 2.0000e+01,  6.1435e-02, -5.9445e-03]), tensor(0.)),\n",
              " (tensor([ 4.0000e+01,  5.8558e-02, -5.9132e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+02,  5.4922e-02, -5.3892e-03]), tensor(0.)),\n",
              " (tensor([ 2.0000e+02,  5.2485e-02, -4.8965e-03]), tensor(0.)),\n",
              " (tensor([ 4.0000e+02,  5.0414e-02, -4.1917e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+03,  4.8036e-02, -3.0689e-03]), tensor(0.)),\n",
              " (tensor([ 0.0500,  0.0782, -0.0049]), tensor(0.)),\n",
              " (tensor([ 0.1000,  0.0767, -0.0039]), tensor(0.)),\n",
              " (tensor([ 0.2000,  0.0755, -0.0028]), tensor(0.)),\n",
              " (tensor([ 0.4000,  0.0750, -0.0023]), tensor(0.)),\n",
              " (tensor([ 1.0000,  0.0736, -0.0026]), tensor(0.)),\n",
              " (tensor([ 2.0000,  0.0729, -0.0032]), tensor(0.)),\n",
              " (tensor([ 4.0000,  0.0715, -0.0042]), tensor(0.)),\n",
              " (tensor([ 1.0000e+01,  6.8578e-02, -5.5536e-03]), tensor(0.)),\n",
              " (tensor([ 2.0000e+01,  6.5428e-02, -6.2551e-03]), tensor(0.)),\n",
              " (tensor([ 4.0000e+01,  6.2342e-02, -6.4357e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+02,  5.8299e-02, -5.8664e-03]), tensor(0.)),\n",
              " (tensor([ 2.0000e+02,  5.5709e-02, -5.2644e-03]), tensor(0.)),\n",
              " (tensor([ 4.0000e+02,  5.3496e-02, -4.3818e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+03,  5.1192e-02, -3.0509e-03]), tensor(0.)),\n",
              " (tensor([ 0.0500,  0.0735, -0.0044]), tensor(0.)),\n",
              " (tensor([ 0.1000,  0.0720, -0.0034]), tensor(0.)),\n",
              " (tensor([ 0.2000,  0.0711, -0.0023]), tensor(0.)),\n",
              " (tensor([ 0.4000,  0.0706, -0.0020]), tensor(0.)),\n",
              " (tensor([ 1.0000,  0.0696, -0.0019]), tensor(0.)),\n",
              " (tensor([ 2.0000,  0.0691, -0.0023]), tensor(0.)),\n",
              " (tensor([ 4.0000e+00,  6.8349e-02, -2.9728e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+01,  6.6075e-02, -4.7372e-03]), tensor(0.)),\n",
              " (tensor([ 2.0000e+01,  6.3371e-02, -5.8504e-03]), tensor(0.)),\n",
              " (tensor([ 4.0000e+01,  6.0204e-02, -6.1337e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+02,  5.6277e-02, -5.8706e-03]), tensor(0.)),\n",
              " (tensor([ 2.0000e+02,  5.3678e-02, -4.9917e-03]), tensor(0.)),\n",
              " (tensor([ 4.0000e+02,  5.1553e-02, -4.2860e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+03,  4.9336e-02, -2.9248e-03]), tensor(0.)),\n",
              " (tensor([ 0.0500,  0.0750, -0.0045]), tensor(0.)),\n",
              " (tensor([ 0.1000,  0.0736, -0.0033]), tensor(0.)),\n",
              " (tensor([ 0.2000,  0.0727, -0.0024]), tensor(0.)),\n",
              " (tensor([ 0.4000,  0.0724, -0.0021]), tensor(0.)),\n",
              " (tensor([ 1.0000,  0.0713, -0.0020]), tensor(0.)),\n",
              " (tensor([ 2.0000,  0.0705, -0.0025]), tensor(0.)),\n",
              " (tensor([ 4.0000e+00,  6.9626e-02, -3.2373e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+01,  6.7319e-02, -4.8935e-03]), tensor(0.)),\n",
              " (tensor([ 2.0000e+01,  6.4682e-02, -5.8295e-03]), tensor(0.)),\n",
              " (tensor([ 4.0000e+01,  6.1710e-02, -6.0087e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+02,  5.7768e-02, -5.3852e-03]), tensor(0.)),\n",
              " (tensor([ 2.0000e+02,  5.5370e-02, -4.8258e-03]), tensor(0.)),\n",
              " (tensor([ 4.0000e+02,  5.3423e-02, -3.8883e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+03,  5.1324e-02, -2.7791e-03]), tensor(0.)),\n",
              " (tensor([ 0.0500,  0.0799, -0.0046]), tensor(0.)),\n",
              " (tensor([ 0.1000,  0.0784, -0.0035]), tensor(0.)),\n",
              " (tensor([ 0.2000,  0.0773, -0.0026]), tensor(0.)),\n",
              " (tensor([ 0.4000,  0.0769, -0.0020]), tensor(0.)),\n",
              " (tensor([ 1.0000,  0.0758, -0.0020]), tensor(0.)),\n",
              " (tensor([ 2.0000,  0.0752, -0.0026]), tensor(0.)),\n",
              " (tensor([ 4.0000e+00,  7.4303e-02, -3.2586e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+01,  7.1812e-02, -4.8716e-03]), tensor(0.)),\n",
              " (tensor([ 2.0000e+01,  6.9079e-02, -5.7905e-03]), tensor(0.)),\n",
              " (tensor([ 4.0000e+01,  6.5966e-02, -6.0232e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+02,  6.2122e-02, -5.7077e-03]), tensor(0.)),\n",
              " (tensor([ 2.0000e+02,  5.9560e-02, -4.7943e-03]), tensor(0.)),\n",
              " (tensor([ 4.0000e+02,  5.7592e-02, -3.9477e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+03,  5.5631e-02, -2.8429e-03]), tensor(0.)),\n",
              " (tensor([ 0.0500,  0.0770, -0.0046]), tensor(0.)),\n",
              " (tensor([ 0.1000,  0.0755, -0.0036]), tensor(0.)),\n",
              " (tensor([ 0.2000,  0.0744, -0.0026]), tensor(0.)),\n",
              " (tensor([ 0.4000,  0.0738, -0.0021]), tensor(0.)),\n",
              " (tensor([ 1.0000,  0.0728, -0.0023]), tensor(0.)),\n",
              " (tensor([ 2.0000,  0.0721, -0.0027]), tensor(0.)),\n",
              " (tensor([ 4.0000e+00,  7.1250e-02, -3.5120e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+01,  6.8566e-02, -5.2681e-03]), tensor(0.)),\n",
              " (tensor([ 2.0000e+01,  6.5698e-02, -6.3446e-03]), tensor(0.)),\n",
              " (tensor([ 4.0000e+01,  6.2095e-02, -6.7705e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+02,  5.7652e-02, -6.2365e-03]), tensor(0.)),\n",
              " (tensor([ 2.0000e+02,  5.4922e-02, -5.4226e-03]), tensor(0.)),\n",
              " (tensor([ 4.0000e+02,  5.2739e-02, -4.4397e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+03,  5.0409e-02, -3.2613e-03]), tensor(0.)),\n",
              " (tensor([ 0.0500,  0.0976, -0.0046]), tensor(0.)),\n",
              " (tensor([ 0.1000,  0.0960, -0.0039]), tensor(0.)),\n",
              " (tensor([ 0.2000,  0.0948, -0.0027]), tensor(0.)),\n",
              " (tensor([ 0.4000,  0.0942, -0.0022]), tensor(0.)),\n",
              " (tensor([ 1.0000,  0.0932, -0.0023]), tensor(0.)),\n",
              " (tensor([ 2.0000,  0.0923, -0.0027]), tensor(0.)),\n",
              " (tensor([ 4.0000e+00,  9.1361e-02, -3.5038e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+01,  8.8793e-02, -4.8719e-03]), tensor(0.)),\n",
              " (tensor([ 2.0000e+01,  8.6085e-02, -5.7506e-03]), tensor(0.)),\n",
              " (tensor([ 4.0000e+01,  8.3177e-02, -6.0026e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+02,  7.9377e-02, -5.6854e-03]), tensor(0.)),\n",
              " (tensor([ 2.0000e+02,  7.6842e-02, -4.9998e-03]), tensor(0.)),\n",
              " (tensor([ 4.0000e+02,  7.4681e-02, -4.1939e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+03,  7.2418e-02, -2.9351e-03]), tensor(0.)),\n",
              " (tensor([ 0.0500,  0.0719, -0.0040]), tensor(0.)),\n",
              " (tensor([ 0.1000,  0.0705, -0.0033]), tensor(0.)),\n",
              " (tensor([ 0.2000,  0.0696, -0.0022]), tensor(0.)),\n",
              " (tensor([ 0.4000,  0.0691, -0.0018]), tensor(0.)),\n",
              " (tensor([ 1.0000,  0.0684, -0.0017]), tensor(0.)),\n",
              " (tensor([ 2.0000,  0.0677, -0.0021]), tensor(0.)),\n",
              " (tensor([ 4.0000e+00,  6.6984e-02, -2.7900e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+01,  6.5122e-02, -4.2382e-03]), tensor(0.)),\n",
              " (tensor([ 2.0000e+01,  6.2783e-02, -5.2291e-03]), tensor(0.)),\n",
              " (tensor([ 4.0000e+01,  5.9880e-02, -5.8211e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+02,  5.6042e-02, -5.5887e-03]), tensor(0.)),\n",
              " (tensor([ 2.0000e+02,  5.3541e-02, -4.9152e-03]), tensor(0.)),\n",
              " (tensor([ 4.0000e+02,  5.1409e-02, -4.2002e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+03,  4.9157e-02, -2.9874e-03]), tensor(0.)),\n",
              " (tensor([ 0.0500,  0.0740, -0.0043]), tensor(0.)),\n",
              " (tensor([ 0.1000,  0.0725, -0.0034]), tensor(0.)),\n",
              " (tensor([ 0.2000,  0.0715, -0.0024]), tensor(0.)),\n",
              " (tensor([ 0.4000,  0.0710, -0.0020]), tensor(0.)),\n",
              " (tensor([ 1.0000,  0.0702, -0.0020]), tensor(0.)),\n",
              " (tensor([ 2.0000,  0.0695, -0.0024]), tensor(0.)),\n",
              " (tensor([ 4.0000e+00,  6.8559e-02, -3.0931e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+01,  6.6522e-02, -4.6062e-03]), tensor(0.)),\n",
              " (tensor([ 2.0000e+01,  6.3936e-02, -5.6080e-03]), tensor(0.)),\n",
              " (tensor([ 4.0000e+01,  6.0867e-02, -6.2270e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+02,  5.6886e-02, -5.8251e-03]), tensor(0.)),\n",
              " (tensor([ 2.0000e+02,  5.4247e-02, -5.1406e-03]), tensor(0.)),\n",
              " (tensor([ 4.0000e+02,  5.2139e-02, -4.3257e-03]), tensor(0.)),\n",
              " (tensor([ 1.0000e+03,  4.9798e-02, -3.0331e-03]), tensor(0.))]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_data[:, 0], train_data[:, 1], \".\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "1fYK2Oi-jCVu",
        "outputId": "fae490a5-1be3-43bd-cbd6-237dd3b9b3a1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4072dba590>]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_data[:, 0], train_data[:, 2], \".\")"
      ],
      "metadata": {
        "id": "ge6r7sg4bf0Z",
        "outputId": "a033a57d-c17e-4d75-b832-a6da2cdb994a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4072f99710>]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_data[:, 1], train_data[:, 2], \"o-\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "5-2HmBR0eEtQ",
        "outputId": "dfa3f01f-c4c2-41de-bbda-37e018c63fb7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4072cddc50>]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "TLc9Tt30oMqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a PyTorch data loader called train_loader.\n",
        "# Data Loader will shuffle the data from train_set and return batches of <batch_size> samples \n",
        "# to be used to train the neural networks.\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set, batch_size=batch_size, drop_last=True, shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "yeBmjp3WkwQB"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "num_epochs = 10000\n",
        "\n",
        "# The binary cross-entropy function is a suitable loss function for training the discriminator \n",
        "# because it considers a binary classification task. \n",
        "# It’s also suitable for training the generator since it feeds its output to the discriminator,\n",
        "# which provides a binary observable output.\n",
        "loss_function = nn.BCELoss()"
      ],
      "metadata": {
        "id": "KWJp-AtaoLYz"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch implements various weight update rules for model training in torch.optim. You’ll use the Adam algorithm to train the discriminator and generator models."
      ],
      "metadata": {
        "id": "OoeUu-71o0QE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
        "optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "fnRht8oRor66"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training loop in which training samples are fed to the models, and their weights are updated to minimize the loss function.\n",
        "\n",
        "As is generally done for all neural networks, the training process consists of two loops, one for the training epochs and the other for the batches for each epoch. Inside the inner loop, you begin preparing the data to train the discriminator:"
      ],
      "metadata": {
        "id": "G-NmDHYxo57l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for n, (real_samples, _) in enumerate(train_loader):\n",
        "        # Data for training the discriminator\n",
        "        real_samples_labels = torch.ones((batch_size, 1))\n",
        "        latent_space_samples = torch.randn((batch_size, 3))\n",
        "        generated_samples = generator(latent_space_samples)\n",
        "        generated_samples_labels = torch.zeros((batch_size, 1))\n",
        "        all_samples = torch.cat((real_samples, generated_samples))\n",
        "        all_samples_labels = torch.cat(\n",
        "            (real_samples_labels, generated_samples_labels)\n",
        "        )\n",
        "\n",
        "        # Training the discriminator\n",
        "        discriminator.zero_grad()\n",
        "        output_discriminator = discriminator(all_samples)\n",
        "        loss_discriminator = loss_function(\n",
        "            output_discriminator, all_samples_labels)\n",
        "        loss_discriminator.backward()\n",
        "        optimizer_discriminator.step()\n",
        "\n",
        "        # Data for training the generator\n",
        "        latent_space_samples = torch.randn((batch_size, 3))\n",
        "\n",
        "        # Training the generator\n",
        "        generator.zero_grad()\n",
        "        generated_samples = generator(latent_space_samples)\n",
        "        output_discriminator_generated = discriminator(generated_samples)\n",
        "        loss_generator = loss_function(\n",
        "            output_discriminator_generated, real_samples_labels\n",
        "        )\n",
        "        loss_generator.backward()\n",
        "        optimizer_generator.step()\n",
        "\n",
        "        # Show loss\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch} Loss D.: {loss_discriminator}\")\n",
        "        print(f\"Epoch: {epoch} Loss G.: {loss_generator}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHuoLPnzpDcW",
        "outputId": "8f194cbc-9c87-4380-ada3-d8e051beda39"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Loss D.: 0.6478396654129028\n",
            "Epoch: 0 Loss G.: 0.7933511734008789\n",
            "Epoch: 10 Loss D.: 0.6427274346351624\n",
            "Epoch: 10 Loss G.: 0.7551420331001282\n",
            "Epoch: 20 Loss D.: 0.6875296235084534\n",
            "Epoch: 20 Loss G.: 0.7623937129974365\n",
            "Epoch: 30 Loss D.: 0.6066382527351379\n",
            "Epoch: 30 Loss G.: 0.782654881477356\n",
            "Epoch: 40 Loss D.: 0.690920352935791\n",
            "Epoch: 40 Loss G.: 0.783189058303833\n",
            "Epoch: 50 Loss D.: 0.6822786331176758\n",
            "Epoch: 50 Loss G.: 0.795692503452301\n",
            "Epoch: 60 Loss D.: 0.6740168333053589\n",
            "Epoch: 60 Loss G.: 0.8126605749130249\n",
            "Epoch: 70 Loss D.: 0.6444815397262573\n",
            "Epoch: 70 Loss G.: 0.8288349509239197\n",
            "Epoch: 80 Loss D.: 0.6580031514167786\n",
            "Epoch: 80 Loss G.: 0.8166574835777283\n",
            "Epoch: 90 Loss D.: 0.6660857200622559\n",
            "Epoch: 90 Loss G.: 0.7368384599685669\n",
            "Epoch: 100 Loss D.: 0.7305794954299927\n",
            "Epoch: 100 Loss G.: 0.7559576630592346\n",
            "Epoch: 110 Loss D.: 0.6556358337402344\n",
            "Epoch: 110 Loss G.: 0.7592928409576416\n",
            "Epoch: 120 Loss D.: 0.6187464594841003\n",
            "Epoch: 120 Loss G.: 0.7652481198310852\n",
            "Epoch: 130 Loss D.: 0.636593759059906\n",
            "Epoch: 130 Loss G.: 0.7928593158721924\n",
            "Epoch: 140 Loss D.: 0.5814005732536316\n",
            "Epoch: 140 Loss G.: 0.6917356848716736\n",
            "Epoch: 150 Loss D.: 0.6733225584030151\n",
            "Epoch: 150 Loss G.: 0.7283570170402527\n",
            "Epoch: 160 Loss D.: 0.6093054413795471\n",
            "Epoch: 160 Loss G.: 0.7954274415969849\n",
            "Epoch: 170 Loss D.: 0.6314436793327332\n",
            "Epoch: 170 Loss G.: 0.8006990551948547\n",
            "Epoch: 180 Loss D.: 0.6236720085144043\n",
            "Epoch: 180 Loss G.: 0.7929159998893738\n",
            "Epoch: 190 Loss D.: 0.6479571461677551\n",
            "Epoch: 190 Loss G.: 0.7846180200576782\n",
            "Epoch: 200 Loss D.: 0.690085232257843\n",
            "Epoch: 200 Loss G.: 0.8122616410255432\n",
            "Epoch: 210 Loss D.: 0.6658113598823547\n",
            "Epoch: 210 Loss G.: 0.7702338695526123\n",
            "Epoch: 220 Loss D.: 0.6462732553482056\n",
            "Epoch: 220 Loss G.: 0.7592087388038635\n",
            "Epoch: 230 Loss D.: 0.625847578048706\n",
            "Epoch: 230 Loss G.: 0.8012123703956604\n",
            "Epoch: 240 Loss D.: 0.6185312867164612\n",
            "Epoch: 240 Loss G.: 0.7447623014450073\n",
            "Epoch: 250 Loss D.: 0.6767758727073669\n",
            "Epoch: 250 Loss G.: 0.7800167798995972\n",
            "Epoch: 260 Loss D.: 0.6119935512542725\n",
            "Epoch: 260 Loss G.: 0.814548134803772\n",
            "Epoch: 270 Loss D.: 0.6565065979957581\n",
            "Epoch: 270 Loss G.: 0.7939763069152832\n",
            "Epoch: 280 Loss D.: 0.6576786041259766\n",
            "Epoch: 280 Loss G.: 0.7784556150436401\n",
            "Epoch: 290 Loss D.: 0.67132967710495\n",
            "Epoch: 290 Loss G.: 0.7300966382026672\n",
            "Epoch: 300 Loss D.: 0.6585286855697632\n",
            "Epoch: 300 Loss G.: 0.7979785799980164\n",
            "Epoch: 310 Loss D.: 0.6359067559242249\n",
            "Epoch: 310 Loss G.: 0.7798532843589783\n",
            "Epoch: 320 Loss D.: 0.6896882653236389\n",
            "Epoch: 320 Loss G.: 0.7035279870033264\n",
            "Epoch: 330 Loss D.: 0.6095149517059326\n",
            "Epoch: 330 Loss G.: 0.7909257411956787\n",
            "Epoch: 340 Loss D.: 0.6313081383705139\n",
            "Epoch: 340 Loss G.: 0.781206488609314\n",
            "Epoch: 350 Loss D.: 0.6127066016197205\n",
            "Epoch: 350 Loss G.: 0.7954143285751343\n",
            "Epoch: 360 Loss D.: 0.6583964824676514\n",
            "Epoch: 360 Loss G.: 0.7096118927001953\n",
            "Epoch: 370 Loss D.: 0.6460298299789429\n",
            "Epoch: 370 Loss G.: 0.7433980703353882\n",
            "Epoch: 380 Loss D.: 0.7120682597160339\n",
            "Epoch: 380 Loss G.: 0.7882055640220642\n",
            "Epoch: 390 Loss D.: 0.682087242603302\n",
            "Epoch: 390 Loss G.: 0.7729219198226929\n",
            "Epoch: 400 Loss D.: 0.6566957235336304\n",
            "Epoch: 400 Loss G.: 0.7902286052703857\n",
            "Epoch: 410 Loss D.: 0.657793402671814\n",
            "Epoch: 410 Loss G.: 0.7964772582054138\n",
            "Epoch: 420 Loss D.: 0.6627081632614136\n",
            "Epoch: 420 Loss G.: 0.8215645551681519\n",
            "Epoch: 430 Loss D.: 0.6675204634666443\n",
            "Epoch: 430 Loss G.: 0.8350031971931458\n",
            "Epoch: 440 Loss D.: 0.6794641017913818\n",
            "Epoch: 440 Loss G.: 0.792474627494812\n",
            "Epoch: 450 Loss D.: 0.6448594927787781\n",
            "Epoch: 450 Loss G.: 0.7974470853805542\n",
            "Epoch: 460 Loss D.: 0.5584111213684082\n",
            "Epoch: 460 Loss G.: 0.7393695712089539\n",
            "Epoch: 470 Loss D.: 0.6260045766830444\n",
            "Epoch: 470 Loss G.: 0.8142556548118591\n",
            "Epoch: 480 Loss D.: 0.6850306391716003\n",
            "Epoch: 480 Loss G.: 0.845869243144989\n",
            "Epoch: 490 Loss D.: 0.6147692203521729\n",
            "Epoch: 490 Loss G.: 0.8566223978996277\n",
            "Epoch: 500 Loss D.: 0.6554589867591858\n",
            "Epoch: 500 Loss G.: 0.8531759977340698\n",
            "Epoch: 510 Loss D.: 0.6952412724494934\n",
            "Epoch: 510 Loss G.: 0.8255234360694885\n",
            "Epoch: 520 Loss D.: 0.6599542498588562\n",
            "Epoch: 520 Loss G.: 0.7598852515220642\n",
            "Epoch: 530 Loss D.: 0.6696515083312988\n",
            "Epoch: 530 Loss G.: 0.7808101773262024\n",
            "Epoch: 540 Loss D.: 0.6214974522590637\n",
            "Epoch: 540 Loss G.: 0.8059833645820618\n",
            "Epoch: 550 Loss D.: 0.6641278266906738\n",
            "Epoch: 550 Loss G.: 0.8199149370193481\n",
            "Epoch: 560 Loss D.: 0.654511034488678\n",
            "Epoch: 560 Loss G.: 0.8618054389953613\n",
            "Epoch: 570 Loss D.: 0.6098529696464539\n",
            "Epoch: 570 Loss G.: 0.8282486796379089\n",
            "Epoch: 580 Loss D.: 0.6985926628112793\n",
            "Epoch: 580 Loss G.: 0.8757967352867126\n",
            "Epoch: 590 Loss D.: 0.6368333697319031\n",
            "Epoch: 590 Loss G.: 0.7703269720077515\n",
            "Epoch: 600 Loss D.: 0.650948703289032\n",
            "Epoch: 600 Loss G.: 0.7924795150756836\n",
            "Epoch: 610 Loss D.: 0.6217523813247681\n",
            "Epoch: 610 Loss G.: 0.7873654961585999\n",
            "Epoch: 620 Loss D.: 0.6494813561439514\n",
            "Epoch: 620 Loss G.: 0.8407030701637268\n",
            "Epoch: 630 Loss D.: 0.6706339716911316\n",
            "Epoch: 630 Loss G.: 0.834140419960022\n",
            "Epoch: 640 Loss D.: 0.6709974408149719\n",
            "Epoch: 640 Loss G.: 0.808322012424469\n",
            "Epoch: 650 Loss D.: 0.666122555732727\n",
            "Epoch: 650 Loss G.: 0.7752320766448975\n",
            "Epoch: 660 Loss D.: 0.6315758228302002\n",
            "Epoch: 660 Loss G.: 0.809014081954956\n",
            "Epoch: 670 Loss D.: 0.6695269346237183\n",
            "Epoch: 670 Loss G.: 0.7667067050933838\n",
            "Epoch: 680 Loss D.: 0.6296287178993225\n",
            "Epoch: 680 Loss G.: 0.7662678956985474\n",
            "Epoch: 690 Loss D.: 0.6498534679412842\n",
            "Epoch: 690 Loss G.: 0.8050042390823364\n",
            "Epoch: 700 Loss D.: 0.626775860786438\n",
            "Epoch: 700 Loss G.: 0.7396860718727112\n",
            "Epoch: 710 Loss D.: 0.6475513577461243\n",
            "Epoch: 710 Loss G.: 0.81053227186203\n",
            "Epoch: 720 Loss D.: 0.6860746145248413\n",
            "Epoch: 720 Loss G.: 0.7548775672912598\n",
            "Epoch: 730 Loss D.: 0.6462283134460449\n",
            "Epoch: 730 Loss G.: 0.7692291736602783\n",
            "Epoch: 740 Loss D.: 0.5431522727012634\n",
            "Epoch: 740 Loss G.: 0.8426560759544373\n",
            "Epoch: 750 Loss D.: 0.6315177083015442\n",
            "Epoch: 750 Loss G.: 0.8240429162979126\n",
            "Epoch: 760 Loss D.: 0.5872276425361633\n",
            "Epoch: 760 Loss G.: 0.7194456458091736\n",
            "Epoch: 770 Loss D.: 0.6412895321846008\n",
            "Epoch: 770 Loss G.: 0.8135546445846558\n",
            "Epoch: 780 Loss D.: 0.6888439655303955\n",
            "Epoch: 780 Loss G.: 0.8387317061424255\n",
            "Epoch: 790 Loss D.: 0.6110093593597412\n",
            "Epoch: 790 Loss G.: 0.8130747079849243\n",
            "Epoch: 800 Loss D.: 0.6278914213180542\n",
            "Epoch: 800 Loss G.: 0.839988112449646\n",
            "Epoch: 810 Loss D.: 0.6333193778991699\n",
            "Epoch: 810 Loss G.: 0.8254907727241516\n",
            "Epoch: 820 Loss D.: 0.6498937606811523\n",
            "Epoch: 820 Loss G.: 0.7172645330429077\n",
            "Epoch: 830 Loss D.: 0.6338527798652649\n",
            "Epoch: 830 Loss G.: 0.8516587615013123\n",
            "Epoch: 840 Loss D.: 0.6263200640678406\n",
            "Epoch: 840 Loss G.: 0.8213969469070435\n",
            "Epoch: 850 Loss D.: 0.554024338722229\n",
            "Epoch: 850 Loss G.: 0.7877302169799805\n",
            "Epoch: 860 Loss D.: 0.6236118078231812\n",
            "Epoch: 860 Loss G.: 0.7852144241333008\n",
            "Epoch: 870 Loss D.: 0.6387033462524414\n",
            "Epoch: 870 Loss G.: 0.7513666749000549\n",
            "Epoch: 880 Loss D.: 0.6693560481071472\n",
            "Epoch: 880 Loss G.: 0.8334016799926758\n",
            "Epoch: 890 Loss D.: 0.6220221519470215\n",
            "Epoch: 890 Loss G.: 0.907061755657196\n",
            "Epoch: 900 Loss D.: 0.6297501921653748\n",
            "Epoch: 900 Loss G.: 0.8033658862113953\n",
            "Epoch: 910 Loss D.: 0.6813243627548218\n",
            "Epoch: 910 Loss G.: 0.8384808301925659\n",
            "Epoch: 920 Loss D.: 0.652827799320221\n",
            "Epoch: 920 Loss G.: 0.7902618646621704\n",
            "Epoch: 930 Loss D.: 0.5957732796669006\n",
            "Epoch: 930 Loss G.: 0.7837981581687927\n",
            "Epoch: 940 Loss D.: 0.6569423675537109\n",
            "Epoch: 940 Loss G.: 0.812360405921936\n",
            "Epoch: 950 Loss D.: 0.6715923547744751\n",
            "Epoch: 950 Loss G.: 0.8493322134017944\n",
            "Epoch: 960 Loss D.: 0.6387112736701965\n",
            "Epoch: 960 Loss G.: 0.7627151012420654\n",
            "Epoch: 970 Loss D.: 0.608830451965332\n",
            "Epoch: 970 Loss G.: 0.8786550164222717\n",
            "Epoch: 980 Loss D.: 0.6090876460075378\n",
            "Epoch: 980 Loss G.: 0.7767357230186462\n",
            "Epoch: 990 Loss D.: 0.6710504293441772\n",
            "Epoch: 990 Loss G.: 0.8107272982597351\n",
            "Epoch: 1000 Loss D.: 0.6776540875434875\n",
            "Epoch: 1000 Loss G.: 0.8122758865356445\n",
            "Epoch: 1010 Loss D.: 0.6218603849411011\n",
            "Epoch: 1010 Loss G.: 0.8209786415100098\n",
            "Epoch: 1020 Loss D.: 0.6675676703453064\n",
            "Epoch: 1020 Loss G.: 0.7339345216751099\n",
            "Epoch: 1030 Loss D.: 0.6839706897735596\n",
            "Epoch: 1030 Loss G.: 0.7946376800537109\n",
            "Epoch: 1040 Loss D.: 0.5772708058357239\n",
            "Epoch: 1040 Loss G.: 0.8613089919090271\n",
            "Epoch: 1050 Loss D.: 0.5874108076095581\n",
            "Epoch: 1050 Loss G.: 0.8366778492927551\n",
            "Epoch: 1060 Loss D.: 0.6202428936958313\n",
            "Epoch: 1060 Loss G.: 0.7533665299415588\n",
            "Epoch: 1070 Loss D.: 0.6339980363845825\n",
            "Epoch: 1070 Loss G.: 0.7703300714492798\n",
            "Epoch: 1080 Loss D.: 0.6687463521957397\n",
            "Epoch: 1080 Loss G.: 0.7947123646736145\n",
            "Epoch: 1090 Loss D.: 0.6154221296310425\n",
            "Epoch: 1090 Loss G.: 0.8137181401252747\n",
            "Epoch: 1100 Loss D.: 0.5860803127288818\n",
            "Epoch: 1100 Loss G.: 0.797784686088562\n",
            "Epoch: 1110 Loss D.: 0.6082170605659485\n",
            "Epoch: 1110 Loss G.: 0.9000634551048279\n",
            "Epoch: 1120 Loss D.: 0.6315532326698303\n",
            "Epoch: 1120 Loss G.: 0.787226140499115\n",
            "Epoch: 1130 Loss D.: 0.6271435618400574\n",
            "Epoch: 1130 Loss G.: 0.7992330193519592\n",
            "Epoch: 1140 Loss D.: 0.737946629524231\n",
            "Epoch: 1140 Loss G.: 0.746842622756958\n",
            "Epoch: 1150 Loss D.: 0.6104692816734314\n",
            "Epoch: 1150 Loss G.: 0.7508893013000488\n",
            "Epoch: 1160 Loss D.: 0.7107974290847778\n",
            "Epoch: 1160 Loss G.: 0.7901033759117126\n",
            "Epoch: 1170 Loss D.: 0.6167348623275757\n",
            "Epoch: 1170 Loss G.: 0.8236229419708252\n",
            "Epoch: 1180 Loss D.: 0.5655748248100281\n",
            "Epoch: 1180 Loss G.: 0.8006654977798462\n",
            "Epoch: 1190 Loss D.: 0.5604047775268555\n",
            "Epoch: 1190 Loss G.: 0.8410998582839966\n",
            "Epoch: 1200 Loss D.: 0.6109973192214966\n",
            "Epoch: 1200 Loss G.: 0.7938390970230103\n",
            "Epoch: 1210 Loss D.: 0.6374338865280151\n",
            "Epoch: 1210 Loss G.: 0.81918865442276\n",
            "Epoch: 1220 Loss D.: 0.6443555355072021\n",
            "Epoch: 1220 Loss G.: 0.8080767393112183\n",
            "Epoch: 1230 Loss D.: 0.616447389125824\n",
            "Epoch: 1230 Loss G.: 0.8041064739227295\n",
            "Epoch: 1240 Loss D.: 0.6290640830993652\n",
            "Epoch: 1240 Loss G.: 0.7450441122055054\n",
            "Epoch: 1250 Loss D.: 0.5563942790031433\n",
            "Epoch: 1250 Loss G.: 0.8361985683441162\n",
            "Epoch: 1260 Loss D.: 0.6080741882324219\n",
            "Epoch: 1260 Loss G.: 0.8703110814094543\n",
            "Epoch: 1270 Loss D.: 0.6245940923690796\n",
            "Epoch: 1270 Loss G.: 0.7851287126541138\n",
            "Epoch: 1280 Loss D.: 0.618707537651062\n",
            "Epoch: 1280 Loss G.: 0.865242063999176\n",
            "Epoch: 1290 Loss D.: 0.5767112374305725\n",
            "Epoch: 1290 Loss G.: 0.8190195560455322\n",
            "Epoch: 1300 Loss D.: 0.6285815238952637\n",
            "Epoch: 1300 Loss G.: 0.7432133555412292\n",
            "Epoch: 1310 Loss D.: 0.6344802975654602\n",
            "Epoch: 1310 Loss G.: 0.8337781429290771\n",
            "Epoch: 1320 Loss D.: 0.5885226130485535\n",
            "Epoch: 1320 Loss G.: 0.8654409646987915\n",
            "Epoch: 1330 Loss D.: 0.5927704572677612\n",
            "Epoch: 1330 Loss G.: 0.8646603226661682\n",
            "Epoch: 1340 Loss D.: 0.6733880043029785\n",
            "Epoch: 1340 Loss G.: 0.8184213638305664\n",
            "Epoch: 1350 Loss D.: 0.5910327434539795\n",
            "Epoch: 1350 Loss G.: 0.7971782684326172\n",
            "Epoch: 1360 Loss D.: 0.6887212991714478\n",
            "Epoch: 1360 Loss G.: 0.7797127366065979\n",
            "Epoch: 1370 Loss D.: 0.6551066040992737\n",
            "Epoch: 1370 Loss G.: 0.7859071493148804\n",
            "Epoch: 1380 Loss D.: 0.644680380821228\n",
            "Epoch: 1380 Loss G.: 0.8161020278930664\n",
            "Epoch: 1390 Loss D.: 0.5854846239089966\n",
            "Epoch: 1390 Loss G.: 0.7547222971916199\n",
            "Epoch: 1400 Loss D.: 0.6373859643936157\n",
            "Epoch: 1400 Loss G.: 0.7970000505447388\n",
            "Epoch: 1410 Loss D.: 0.6236124634742737\n",
            "Epoch: 1410 Loss G.: 0.9189797639846802\n",
            "Epoch: 1420 Loss D.: 0.6980336904525757\n",
            "Epoch: 1420 Loss G.: 0.8732368350028992\n",
            "Epoch: 1430 Loss D.: 0.6557802557945251\n",
            "Epoch: 1430 Loss G.: 0.870582640171051\n",
            "Epoch: 1440 Loss D.: 0.5791563391685486\n",
            "Epoch: 1440 Loss G.: 0.8232297897338867\n",
            "Epoch: 1450 Loss D.: 0.6110813617706299\n",
            "Epoch: 1450 Loss G.: 0.8303239941596985\n",
            "Epoch: 1460 Loss D.: 0.651777446269989\n",
            "Epoch: 1460 Loss G.: 0.8696438670158386\n",
            "Epoch: 1470 Loss D.: 0.5820023417472839\n",
            "Epoch: 1470 Loss G.: 0.7717782855033875\n",
            "Epoch: 1480 Loss D.: 0.5943847894668579\n",
            "Epoch: 1480 Loss G.: 0.8239724040031433\n",
            "Epoch: 1490 Loss D.: 0.5741984248161316\n",
            "Epoch: 1490 Loss G.: 0.8126727938652039\n",
            "Epoch: 1500 Loss D.: 0.6300702691078186\n",
            "Epoch: 1500 Loss G.: 0.8166388869285583\n",
            "Epoch: 1510 Loss D.: 0.6428888440132141\n",
            "Epoch: 1510 Loss G.: 0.827683687210083\n",
            "Epoch: 1520 Loss D.: 0.6086748242378235\n",
            "Epoch: 1520 Loss G.: 0.8145390748977661\n",
            "Epoch: 1530 Loss D.: 0.5989444255828857\n",
            "Epoch: 1530 Loss G.: 0.8357990980148315\n",
            "Epoch: 1540 Loss D.: 0.828357458114624\n",
            "Epoch: 1540 Loss G.: 0.7619714736938477\n",
            "Epoch: 1550 Loss D.: 0.5889171957969666\n",
            "Epoch: 1550 Loss G.: 0.8204754590988159\n",
            "Epoch: 1560 Loss D.: 0.6407017111778259\n",
            "Epoch: 1560 Loss G.: 0.8246570825576782\n",
            "Epoch: 1570 Loss D.: 0.6798882484436035\n",
            "Epoch: 1570 Loss G.: 0.8369333148002625\n",
            "Epoch: 1580 Loss D.: 0.6442881226539612\n",
            "Epoch: 1580 Loss G.: 0.7862923741340637\n",
            "Epoch: 1590 Loss D.: 0.5924129486083984\n",
            "Epoch: 1590 Loss G.: 0.7924377918243408\n",
            "Epoch: 1600 Loss D.: 0.5545852184295654\n",
            "Epoch: 1600 Loss G.: 0.7876294255256653\n",
            "Epoch: 1610 Loss D.: 0.6032388210296631\n",
            "Epoch: 1610 Loss G.: 0.7641634345054626\n",
            "Epoch: 1620 Loss D.: 0.6315809488296509\n",
            "Epoch: 1620 Loss G.: 0.7967478632926941\n",
            "Epoch: 1630 Loss D.: 0.6169607639312744\n",
            "Epoch: 1630 Loss G.: 0.8025842905044556\n",
            "Epoch: 1640 Loss D.: 0.6370565891265869\n",
            "Epoch: 1640 Loss G.: 0.8664590716362\n",
            "Epoch: 1650 Loss D.: 0.6304567456245422\n",
            "Epoch: 1650 Loss G.: 0.8358402252197266\n",
            "Epoch: 1660 Loss D.: 0.6282126307487488\n",
            "Epoch: 1660 Loss G.: 0.7396363615989685\n",
            "Epoch: 1670 Loss D.: 0.6389548778533936\n",
            "Epoch: 1670 Loss G.: 0.810909628868103\n",
            "Epoch: 1680 Loss D.: 0.5928228497505188\n",
            "Epoch: 1680 Loss G.: 0.850920557975769\n",
            "Epoch: 1690 Loss D.: 0.7264504432678223\n",
            "Epoch: 1690 Loss G.: 0.761726438999176\n",
            "Epoch: 1700 Loss D.: 0.682977020740509\n",
            "Epoch: 1700 Loss G.: 0.8425018191337585\n",
            "Epoch: 1710 Loss D.: 0.6466495990753174\n",
            "Epoch: 1710 Loss G.: 0.8656442761421204\n",
            "Epoch: 1720 Loss D.: 0.5798585414886475\n",
            "Epoch: 1720 Loss G.: 0.8840392827987671\n",
            "Epoch: 1730 Loss D.: 0.6592943668365479\n",
            "Epoch: 1730 Loss G.: 0.8238413333892822\n",
            "Epoch: 1740 Loss D.: 0.6331883668899536\n",
            "Epoch: 1740 Loss G.: 0.7821676731109619\n",
            "Epoch: 1750 Loss D.: 0.6122399568557739\n",
            "Epoch: 1750 Loss G.: 0.7682005167007446\n",
            "Epoch: 1760 Loss D.: 0.5804322361946106\n",
            "Epoch: 1760 Loss G.: 0.7798136472702026\n",
            "Epoch: 1770 Loss D.: 0.6511804461479187\n",
            "Epoch: 1770 Loss G.: 0.8641130328178406\n",
            "Epoch: 1780 Loss D.: 0.6341813802719116\n",
            "Epoch: 1780 Loss G.: 0.8145960569381714\n",
            "Epoch: 1790 Loss D.: 0.6478855013847351\n",
            "Epoch: 1790 Loss G.: 0.8397929072380066\n",
            "Epoch: 1800 Loss D.: 0.6003522276878357\n",
            "Epoch: 1800 Loss G.: 0.8207686543464661\n",
            "Epoch: 1810 Loss D.: 0.5891094207763672\n",
            "Epoch: 1810 Loss G.: 0.8279032707214355\n",
            "Epoch: 1820 Loss D.: 0.7074989080429077\n",
            "Epoch: 1820 Loss G.: 0.8417498469352722\n",
            "Epoch: 1830 Loss D.: 0.6009870171546936\n",
            "Epoch: 1830 Loss G.: 0.8255444765090942\n",
            "Epoch: 1840 Loss D.: 0.6866053342819214\n",
            "Epoch: 1840 Loss G.: 0.8400800228118896\n",
            "Epoch: 1850 Loss D.: 0.5774651169776917\n",
            "Epoch: 1850 Loss G.: 0.7974265217781067\n",
            "Epoch: 1860 Loss D.: 0.6017765998840332\n",
            "Epoch: 1860 Loss G.: 0.7640106081962585\n",
            "Epoch: 1870 Loss D.: 0.5773606300354004\n",
            "Epoch: 1870 Loss G.: 0.7903967499732971\n",
            "Epoch: 1880 Loss D.: 0.7177188396453857\n",
            "Epoch: 1880 Loss G.: 0.7825629115104675\n",
            "Epoch: 1890 Loss D.: 0.6149548292160034\n",
            "Epoch: 1890 Loss G.: 0.7940395474433899\n",
            "Epoch: 1900 Loss D.: 0.6546531319618225\n",
            "Epoch: 1900 Loss G.: 0.8185549974441528\n",
            "Epoch: 1910 Loss D.: 0.6560741662979126\n",
            "Epoch: 1910 Loss G.: 0.7603535652160645\n",
            "Epoch: 1920 Loss D.: 0.6220388412475586\n",
            "Epoch: 1920 Loss G.: 0.889071524143219\n",
            "Epoch: 1930 Loss D.: 0.6033416390419006\n",
            "Epoch: 1930 Loss G.: 0.8088514804840088\n",
            "Epoch: 1940 Loss D.: 0.6240129470825195\n",
            "Epoch: 1940 Loss G.: 0.8889564871788025\n",
            "Epoch: 1950 Loss D.: 0.601506769657135\n",
            "Epoch: 1950 Loss G.: 0.8739854097366333\n",
            "Epoch: 1960 Loss D.: 0.611625075340271\n",
            "Epoch: 1960 Loss G.: 0.7967366576194763\n",
            "Epoch: 1970 Loss D.: 0.6822291612625122\n",
            "Epoch: 1970 Loss G.: 0.8533951044082642\n",
            "Epoch: 1980 Loss D.: 0.6037503480911255\n",
            "Epoch: 1980 Loss G.: 0.8588098883628845\n",
            "Epoch: 1990 Loss D.: 0.6501410603523254\n",
            "Epoch: 1990 Loss G.: 0.8118284940719604\n",
            "Epoch: 2000 Loss D.: 0.6089515686035156\n",
            "Epoch: 2000 Loss G.: 0.79510498046875\n",
            "Epoch: 2010 Loss D.: 0.6274774670600891\n",
            "Epoch: 2010 Loss G.: 0.7478505373001099\n",
            "Epoch: 2020 Loss D.: 0.7523829936981201\n",
            "Epoch: 2020 Loss G.: 0.8592941761016846\n",
            "Epoch: 2030 Loss D.: 0.6013054847717285\n",
            "Epoch: 2030 Loss G.: 0.796097457408905\n",
            "Epoch: 2040 Loss D.: 0.6097373962402344\n",
            "Epoch: 2040 Loss G.: 0.8118408918380737\n",
            "Epoch: 2050 Loss D.: 0.6340611577033997\n",
            "Epoch: 2050 Loss G.: 0.8647317886352539\n",
            "Epoch: 2060 Loss D.: 0.6170588135719299\n",
            "Epoch: 2060 Loss G.: 0.8086835145950317\n",
            "Epoch: 2070 Loss D.: 0.6147608160972595\n",
            "Epoch: 2070 Loss G.: 0.7826067805290222\n",
            "Epoch: 2080 Loss D.: 0.6202676296234131\n",
            "Epoch: 2080 Loss G.: 0.8078816533088684\n",
            "Epoch: 2090 Loss D.: 0.6063537001609802\n",
            "Epoch: 2090 Loss G.: 0.8097783923149109\n",
            "Epoch: 2100 Loss D.: 0.5989402532577515\n",
            "Epoch: 2100 Loss G.: 0.8108508586883545\n",
            "Epoch: 2110 Loss D.: 0.6933503746986389\n",
            "Epoch: 2110 Loss G.: 0.8435537219047546\n",
            "Epoch: 2120 Loss D.: 0.6392478346824646\n",
            "Epoch: 2120 Loss G.: 0.8969470858573914\n",
            "Epoch: 2130 Loss D.: 0.6656830906867981\n",
            "Epoch: 2130 Loss G.: 0.841710090637207\n",
            "Epoch: 2140 Loss D.: 0.6197850704193115\n",
            "Epoch: 2140 Loss G.: 0.8219747543334961\n",
            "Epoch: 2150 Loss D.: 0.6218047142028809\n",
            "Epoch: 2150 Loss G.: 0.758823573589325\n",
            "Epoch: 2160 Loss D.: 0.6474842429161072\n",
            "Epoch: 2160 Loss G.: 0.8091254234313965\n",
            "Epoch: 2170 Loss D.: 0.5824582576751709\n",
            "Epoch: 2170 Loss G.: 0.8963098526000977\n",
            "Epoch: 2180 Loss D.: 0.6110317707061768\n",
            "Epoch: 2180 Loss G.: 0.7701831459999084\n",
            "Epoch: 2190 Loss D.: 0.6436792612075806\n",
            "Epoch: 2190 Loss G.: 0.7931998372077942\n",
            "Epoch: 2200 Loss D.: 0.6116468906402588\n",
            "Epoch: 2200 Loss G.: 0.8047249913215637\n",
            "Epoch: 2210 Loss D.: 0.6314865946769714\n",
            "Epoch: 2210 Loss G.: 0.7730599641799927\n",
            "Epoch: 2220 Loss D.: 0.620954155921936\n",
            "Epoch: 2220 Loss G.: 0.8824061155319214\n",
            "Epoch: 2230 Loss D.: 0.6103028059005737\n",
            "Epoch: 2230 Loss G.: 0.8969680070877075\n",
            "Epoch: 2240 Loss D.: 0.6422312259674072\n",
            "Epoch: 2240 Loss G.: 0.8272569179534912\n",
            "Epoch: 2250 Loss D.: 0.6185245513916016\n",
            "Epoch: 2250 Loss G.: 0.8176222443580627\n",
            "Epoch: 2260 Loss D.: 0.6572152376174927\n",
            "Epoch: 2260 Loss G.: 0.8155639171600342\n",
            "Epoch: 2270 Loss D.: 0.6167119145393372\n",
            "Epoch: 2270 Loss G.: 0.848190426826477\n",
            "Epoch: 2280 Loss D.: 0.5909601449966431\n",
            "Epoch: 2280 Loss G.: 0.8368342518806458\n",
            "Epoch: 2290 Loss D.: 0.658821702003479\n",
            "Epoch: 2290 Loss G.: 0.7993139028549194\n",
            "Epoch: 2300 Loss D.: 0.5965712070465088\n",
            "Epoch: 2300 Loss G.: 0.8085893392562866\n",
            "Epoch: 2310 Loss D.: 0.6040536761283875\n",
            "Epoch: 2310 Loss G.: 0.7861908674240112\n",
            "Epoch: 2320 Loss D.: 0.6408050060272217\n",
            "Epoch: 2320 Loss G.: 0.8509154319763184\n",
            "Epoch: 2330 Loss D.: 0.6066669225692749\n",
            "Epoch: 2330 Loss G.: 0.851594865322113\n",
            "Epoch: 2340 Loss D.: 0.7122200131416321\n",
            "Epoch: 2340 Loss G.: 0.8557174801826477\n",
            "Epoch: 2350 Loss D.: 0.5595170259475708\n",
            "Epoch: 2350 Loss G.: 0.8459404706954956\n",
            "Epoch: 2360 Loss D.: 0.6042017340660095\n",
            "Epoch: 2360 Loss G.: 0.8341817855834961\n",
            "Epoch: 2370 Loss D.: 0.6587582230567932\n",
            "Epoch: 2370 Loss G.: 0.8210635185241699\n",
            "Epoch: 2380 Loss D.: 0.6227074265480042\n",
            "Epoch: 2380 Loss G.: 0.803187370300293\n",
            "Epoch: 2390 Loss D.: 0.6096031069755554\n",
            "Epoch: 2390 Loss G.: 0.8202388286590576\n",
            "Epoch: 2400 Loss D.: 0.72907954454422\n",
            "Epoch: 2400 Loss G.: 0.8027885556221008\n",
            "Epoch: 2410 Loss D.: 0.6642917394638062\n",
            "Epoch: 2410 Loss G.: 0.7905627489089966\n",
            "Epoch: 2420 Loss D.: 0.6417869925498962\n",
            "Epoch: 2420 Loss G.: 0.8356533050537109\n",
            "Epoch: 2430 Loss D.: 0.6374151706695557\n",
            "Epoch: 2430 Loss G.: 0.8028375506401062\n",
            "Epoch: 2440 Loss D.: 0.634062647819519\n",
            "Epoch: 2440 Loss G.: 0.8686515092849731\n",
            "Epoch: 2450 Loss D.: 0.6056199073791504\n",
            "Epoch: 2450 Loss G.: 0.841208815574646\n",
            "Epoch: 2460 Loss D.: 0.6135705709457397\n",
            "Epoch: 2460 Loss G.: 0.8121999502182007\n",
            "Epoch: 2470 Loss D.: 0.603320837020874\n",
            "Epoch: 2470 Loss G.: 0.7663945555686951\n",
            "Epoch: 2480 Loss D.: 0.6190868616104126\n",
            "Epoch: 2480 Loss G.: 0.7467573881149292\n",
            "Epoch: 2490 Loss D.: 0.6224082708358765\n",
            "Epoch: 2490 Loss G.: 0.8602972626686096\n",
            "Epoch: 2500 Loss D.: 0.6132934093475342\n",
            "Epoch: 2500 Loss G.: 0.8801648616790771\n",
            "Epoch: 2510 Loss D.: 0.6162351965904236\n",
            "Epoch: 2510 Loss G.: 0.8238918781280518\n",
            "Epoch: 2520 Loss D.: 0.5949235558509827\n",
            "Epoch: 2520 Loss G.: 0.8238605260848999\n",
            "Epoch: 2530 Loss D.: 0.6352136135101318\n",
            "Epoch: 2530 Loss G.: 0.9067345857620239\n",
            "Epoch: 2540 Loss D.: 0.646004319190979\n",
            "Epoch: 2540 Loss G.: 0.8321525454521179\n",
            "Epoch: 2550 Loss D.: 0.6543579697608948\n",
            "Epoch: 2550 Loss G.: 0.791695237159729\n",
            "Epoch: 2560 Loss D.: 0.582324743270874\n",
            "Epoch: 2560 Loss G.: 0.8075886964797974\n",
            "Epoch: 2570 Loss D.: 0.5985785126686096\n",
            "Epoch: 2570 Loss G.: 0.814542293548584\n",
            "Epoch: 2580 Loss D.: 0.6598316431045532\n",
            "Epoch: 2580 Loss G.: 0.8084325194358826\n",
            "Epoch: 2590 Loss D.: 0.6263397932052612\n",
            "Epoch: 2590 Loss G.: 0.7998363375663757\n",
            "Epoch: 2600 Loss D.: 0.5994184613227844\n",
            "Epoch: 2600 Loss G.: 0.8340649008750916\n",
            "Epoch: 2610 Loss D.: 0.6454269886016846\n",
            "Epoch: 2610 Loss G.: 0.871733546257019\n",
            "Epoch: 2620 Loss D.: 0.6183385848999023\n",
            "Epoch: 2620 Loss G.: 0.780992329120636\n",
            "Epoch: 2630 Loss D.: 0.6965152025222778\n",
            "Epoch: 2630 Loss G.: 0.9102616310119629\n",
            "Epoch: 2640 Loss D.: 0.665270984172821\n",
            "Epoch: 2640 Loss G.: 0.8114373087882996\n",
            "Epoch: 2650 Loss D.: 0.5308098196983337\n",
            "Epoch: 2650 Loss G.: 0.8222453594207764\n",
            "Epoch: 2660 Loss D.: 0.5913072228431702\n",
            "Epoch: 2660 Loss G.: 0.8969389200210571\n",
            "Epoch: 2670 Loss D.: 0.6349905729293823\n",
            "Epoch: 2670 Loss G.: 0.8680975437164307\n",
            "Epoch: 2680 Loss D.: 0.6622495651245117\n",
            "Epoch: 2680 Loss G.: 0.8908419609069824\n",
            "Epoch: 2690 Loss D.: 0.6529654264450073\n",
            "Epoch: 2690 Loss G.: 0.9042333364486694\n",
            "Epoch: 2700 Loss D.: 0.5877141356468201\n",
            "Epoch: 2700 Loss G.: 0.7735951542854309\n",
            "Epoch: 2710 Loss D.: 0.6315286755561829\n",
            "Epoch: 2710 Loss G.: 0.8417955040931702\n",
            "Epoch: 2720 Loss D.: 0.6790468096733093\n",
            "Epoch: 2720 Loss G.: 0.7630124688148499\n",
            "Epoch: 2730 Loss D.: 0.6539168357849121\n",
            "Epoch: 2730 Loss G.: 0.8379538059234619\n",
            "Epoch: 2740 Loss D.: 0.6579843163490295\n",
            "Epoch: 2740 Loss G.: 0.854392945766449\n",
            "Epoch: 2750 Loss D.: 0.6402618288993835\n",
            "Epoch: 2750 Loss G.: 0.8794999718666077\n",
            "Epoch: 2760 Loss D.: 0.5433631539344788\n",
            "Epoch: 2760 Loss G.: 0.9000700116157532\n",
            "Epoch: 2770 Loss D.: 0.6691926717758179\n",
            "Epoch: 2770 Loss G.: 0.8345628380775452\n",
            "Epoch: 2780 Loss D.: 0.6311138272285461\n",
            "Epoch: 2780 Loss G.: 0.8436615467071533\n",
            "Epoch: 2790 Loss D.: 0.695845365524292\n",
            "Epoch: 2790 Loss G.: 0.8065575361251831\n",
            "Epoch: 2800 Loss D.: 0.6417970061302185\n",
            "Epoch: 2800 Loss G.: 0.7505382299423218\n",
            "Epoch: 2810 Loss D.: 0.5550574660301208\n",
            "Epoch: 2810 Loss G.: 0.7742739915847778\n",
            "Epoch: 2820 Loss D.: 0.5788264870643616\n",
            "Epoch: 2820 Loss G.: 0.8447224497795105\n",
            "Epoch: 2830 Loss D.: 0.5753523707389832\n",
            "Epoch: 2830 Loss G.: 0.8190449476242065\n",
            "Epoch: 2840 Loss D.: 0.6137216687202454\n",
            "Epoch: 2840 Loss G.: 0.8007315397262573\n",
            "Epoch: 2850 Loss D.: 0.6630046963691711\n",
            "Epoch: 2850 Loss G.: 0.8584088683128357\n",
            "Epoch: 2860 Loss D.: 0.5875819325447083\n",
            "Epoch: 2860 Loss G.: 0.8415461182594299\n",
            "Epoch: 2870 Loss D.: 0.6212279200553894\n",
            "Epoch: 2870 Loss G.: 0.8200643062591553\n",
            "Epoch: 2880 Loss D.: 0.7523373365402222\n",
            "Epoch: 2880 Loss G.: 0.8112177848815918\n",
            "Epoch: 2890 Loss D.: 0.5964139103889465\n",
            "Epoch: 2890 Loss G.: 0.8817061185836792\n",
            "Epoch: 2900 Loss D.: 0.606370210647583\n",
            "Epoch: 2900 Loss G.: 0.7834480404853821\n",
            "Epoch: 2910 Loss D.: 0.645187497138977\n",
            "Epoch: 2910 Loss G.: 0.875717043876648\n",
            "Epoch: 2920 Loss D.: 0.6084556579589844\n",
            "Epoch: 2920 Loss G.: 0.8138265609741211\n",
            "Epoch: 2930 Loss D.: 0.5949890613555908\n",
            "Epoch: 2930 Loss G.: 0.9330583214759827\n",
            "Epoch: 2940 Loss D.: 0.5927958488464355\n",
            "Epoch: 2940 Loss G.: 0.8901708126068115\n",
            "Epoch: 2950 Loss D.: 0.6226200461387634\n",
            "Epoch: 2950 Loss G.: 0.7356505990028381\n",
            "Epoch: 2960 Loss D.: 0.6581183075904846\n",
            "Epoch: 2960 Loss G.: 0.7933318018913269\n",
            "Epoch: 2970 Loss D.: 0.5952711701393127\n",
            "Epoch: 2970 Loss G.: 0.8385816812515259\n",
            "Epoch: 2980 Loss D.: 0.6026524901390076\n",
            "Epoch: 2980 Loss G.: 0.8564049005508423\n",
            "Epoch: 2990 Loss D.: 0.6643600463867188\n",
            "Epoch: 2990 Loss G.: 0.7905138731002808\n",
            "Epoch: 3000 Loss D.: 0.5829492211341858\n",
            "Epoch: 3000 Loss G.: 0.7724506855010986\n",
            "Epoch: 3010 Loss D.: 0.6794492602348328\n",
            "Epoch: 3010 Loss G.: 0.9083079695701599\n",
            "Epoch: 3020 Loss D.: 0.6454215049743652\n",
            "Epoch: 3020 Loss G.: 0.7974565625190735\n",
            "Epoch: 3030 Loss D.: 0.615418553352356\n",
            "Epoch: 3030 Loss G.: 0.8107852935791016\n",
            "Epoch: 3040 Loss D.: 0.6391457319259644\n",
            "Epoch: 3040 Loss G.: 0.7834764122962952\n",
            "Epoch: 3050 Loss D.: 0.6454580426216125\n",
            "Epoch: 3050 Loss G.: 0.8474394083023071\n",
            "Epoch: 3060 Loss D.: 0.6580771803855896\n",
            "Epoch: 3060 Loss G.: 0.7997885942459106\n",
            "Epoch: 3070 Loss D.: 0.6528738737106323\n",
            "Epoch: 3070 Loss G.: 0.7616695165634155\n",
            "Epoch: 3080 Loss D.: 0.5964062213897705\n",
            "Epoch: 3080 Loss G.: 0.7803314924240112\n",
            "Epoch: 3090 Loss D.: 0.6896048188209534\n",
            "Epoch: 3090 Loss G.: 0.8072781562805176\n",
            "Epoch: 3100 Loss D.: 0.6930096745491028\n",
            "Epoch: 3100 Loss G.: 0.7938880324363708\n",
            "Epoch: 3110 Loss D.: 0.655902624130249\n",
            "Epoch: 3110 Loss G.: 0.8182655572891235\n",
            "Epoch: 3120 Loss D.: 0.6201402544975281\n",
            "Epoch: 3120 Loss G.: 0.8917880654335022\n",
            "Epoch: 3130 Loss D.: 0.5853478908538818\n",
            "Epoch: 3130 Loss G.: 0.8986687660217285\n",
            "Epoch: 3140 Loss D.: 0.574532687664032\n",
            "Epoch: 3140 Loss G.: 0.7735763788223267\n",
            "Epoch: 3150 Loss D.: 0.6248899102210999\n",
            "Epoch: 3150 Loss G.: 0.7913687229156494\n",
            "Epoch: 3160 Loss D.: 0.5978215932846069\n",
            "Epoch: 3160 Loss G.: 0.8073804378509521\n",
            "Epoch: 3170 Loss D.: 0.6808026432991028\n",
            "Epoch: 3170 Loss G.: 0.8402045965194702\n",
            "Epoch: 3180 Loss D.: 0.6305635571479797\n",
            "Epoch: 3180 Loss G.: 0.8184201121330261\n",
            "Epoch: 3190 Loss D.: 0.646503210067749\n",
            "Epoch: 3190 Loss G.: 0.7791903018951416\n",
            "Epoch: 3200 Loss D.: 0.7003963589668274\n",
            "Epoch: 3200 Loss G.: 0.8536993265151978\n",
            "Epoch: 3210 Loss D.: 0.6024488806724548\n",
            "Epoch: 3210 Loss G.: 0.9046421051025391\n",
            "Epoch: 3220 Loss D.: 0.5958764553070068\n",
            "Epoch: 3220 Loss G.: 0.7728599309921265\n",
            "Epoch: 3230 Loss D.: 0.6013548374176025\n",
            "Epoch: 3230 Loss G.: 0.8891459703445435\n",
            "Epoch: 3240 Loss D.: 0.584033727645874\n",
            "Epoch: 3240 Loss G.: 0.8185445070266724\n",
            "Epoch: 3250 Loss D.: 0.6501038074493408\n",
            "Epoch: 3250 Loss G.: 0.8713141679763794\n",
            "Epoch: 3260 Loss D.: 0.615451455116272\n",
            "Epoch: 3260 Loss G.: 0.8227140307426453\n",
            "Epoch: 3270 Loss D.: 0.6100221276283264\n",
            "Epoch: 3270 Loss G.: 0.8718205690383911\n",
            "Epoch: 3280 Loss D.: 0.6041319966316223\n",
            "Epoch: 3280 Loss G.: 0.8019881248474121\n",
            "Epoch: 3290 Loss D.: 0.6397604942321777\n",
            "Epoch: 3290 Loss G.: 0.8737963438034058\n",
            "Epoch: 3300 Loss D.: 0.6519942879676819\n",
            "Epoch: 3300 Loss G.: 0.8673886656761169\n",
            "Epoch: 3310 Loss D.: 0.6449181437492371\n",
            "Epoch: 3310 Loss G.: 0.792490541934967\n",
            "Epoch: 3320 Loss D.: 0.6284047961235046\n",
            "Epoch: 3320 Loss G.: 0.809344470500946\n",
            "Epoch: 3330 Loss D.: 0.5864448547363281\n",
            "Epoch: 3330 Loss G.: 0.7997813820838928\n",
            "Epoch: 3340 Loss D.: 0.5795061588287354\n",
            "Epoch: 3340 Loss G.: 0.8249278664588928\n",
            "Epoch: 3350 Loss D.: 0.6209438443183899\n",
            "Epoch: 3350 Loss G.: 0.8635397553443909\n",
            "Epoch: 3360 Loss D.: 0.629122793674469\n",
            "Epoch: 3360 Loss G.: 0.916027843952179\n",
            "Epoch: 3370 Loss D.: 0.6318047642707825\n",
            "Epoch: 3370 Loss G.: 0.820599377155304\n",
            "Epoch: 3380 Loss D.: 0.6221762895584106\n",
            "Epoch: 3380 Loss G.: 0.8107671737670898\n",
            "Epoch: 3390 Loss D.: 0.6193274259567261\n",
            "Epoch: 3390 Loss G.: 0.815619170665741\n",
            "Epoch: 3400 Loss D.: 0.6150747537612915\n",
            "Epoch: 3400 Loss G.: 0.878802478313446\n",
            "Epoch: 3410 Loss D.: 0.6685468554496765\n",
            "Epoch: 3410 Loss G.: 0.7958372235298157\n",
            "Epoch: 3420 Loss D.: 0.627811849117279\n",
            "Epoch: 3420 Loss G.: 0.895584225654602\n",
            "Epoch: 3430 Loss D.: 0.6477227210998535\n",
            "Epoch: 3430 Loss G.: 0.8401378393173218\n",
            "Epoch: 3440 Loss D.: 0.5900018811225891\n",
            "Epoch: 3440 Loss G.: 0.810173511505127\n",
            "Epoch: 3450 Loss D.: 0.6635571718215942\n",
            "Epoch: 3450 Loss G.: 0.8116083145141602\n",
            "Epoch: 3460 Loss D.: 0.6528888940811157\n",
            "Epoch: 3460 Loss G.: 0.8172938227653503\n",
            "Epoch: 3470 Loss D.: 0.604824960231781\n",
            "Epoch: 3470 Loss G.: 0.8683481216430664\n",
            "Epoch: 3480 Loss D.: 0.6722331047058105\n",
            "Epoch: 3480 Loss G.: 0.8587011098861694\n",
            "Epoch: 3490 Loss D.: 0.6382080912590027\n",
            "Epoch: 3490 Loss G.: 0.85347580909729\n",
            "Epoch: 3500 Loss D.: 0.6424710154533386\n",
            "Epoch: 3500 Loss G.: 0.7805320620536804\n",
            "Epoch: 3510 Loss D.: 0.6049011945724487\n",
            "Epoch: 3510 Loss G.: 0.9356241226196289\n",
            "Epoch: 3520 Loss D.: 0.5895124673843384\n",
            "Epoch: 3520 Loss G.: 0.7889760136604309\n",
            "Epoch: 3530 Loss D.: 0.6388401985168457\n",
            "Epoch: 3530 Loss G.: 0.8079985976219177\n",
            "Epoch: 3540 Loss D.: 0.7125629186630249\n",
            "Epoch: 3540 Loss G.: 0.8296705484390259\n",
            "Epoch: 3550 Loss D.: 0.6213420033454895\n",
            "Epoch: 3550 Loss G.: 0.9667458534240723\n",
            "Epoch: 3560 Loss D.: 0.614650309085846\n",
            "Epoch: 3560 Loss G.: 0.8432391285896301\n",
            "Epoch: 3570 Loss D.: 0.6803494691848755\n",
            "Epoch: 3570 Loss G.: 0.8175547122955322\n",
            "Epoch: 3580 Loss D.: 0.6497328281402588\n",
            "Epoch: 3580 Loss G.: 0.853309690952301\n",
            "Epoch: 3590 Loss D.: 0.6007725596427917\n",
            "Epoch: 3590 Loss G.: 0.855428159236908\n",
            "Epoch: 3600 Loss D.: 0.633240282535553\n",
            "Epoch: 3600 Loss G.: 0.8061980605125427\n",
            "Epoch: 3610 Loss D.: 0.6251432299613953\n",
            "Epoch: 3610 Loss G.: 0.9690916538238525\n",
            "Epoch: 3620 Loss D.: 0.6374592185020447\n",
            "Epoch: 3620 Loss G.: 0.7961200475692749\n",
            "Epoch: 3630 Loss D.: 0.7026137709617615\n",
            "Epoch: 3630 Loss G.: 0.7767918109893799\n",
            "Epoch: 3640 Loss D.: 0.661210834980011\n",
            "Epoch: 3640 Loss G.: 0.8137016296386719\n",
            "Epoch: 3650 Loss D.: 0.6269365549087524\n",
            "Epoch: 3650 Loss G.: 0.866746723651886\n",
            "Epoch: 3660 Loss D.: 0.6197490692138672\n",
            "Epoch: 3660 Loss G.: 0.8173058032989502\n",
            "Epoch: 3670 Loss D.: 0.6394761800765991\n",
            "Epoch: 3670 Loss G.: 0.8317025303840637\n",
            "Epoch: 3680 Loss D.: 0.5853245258331299\n",
            "Epoch: 3680 Loss G.: 0.8344035148620605\n",
            "Epoch: 3690 Loss D.: 0.6467781066894531\n",
            "Epoch: 3690 Loss G.: 0.8729978203773499\n",
            "Epoch: 3700 Loss D.: 0.5774156451225281\n",
            "Epoch: 3700 Loss G.: 0.843924343585968\n",
            "Epoch: 3710 Loss D.: 0.6188029050827026\n",
            "Epoch: 3710 Loss G.: 0.803374171257019\n",
            "Epoch: 3720 Loss D.: 0.6695078015327454\n",
            "Epoch: 3720 Loss G.: 0.8945996165275574\n",
            "Epoch: 3730 Loss D.: 0.6382303237915039\n",
            "Epoch: 3730 Loss G.: 0.8967986702919006\n",
            "Epoch: 3740 Loss D.: 0.598963737487793\n",
            "Epoch: 3740 Loss G.: 0.885733962059021\n",
            "Epoch: 3750 Loss D.: 0.6045901775360107\n",
            "Epoch: 3750 Loss G.: 0.8478996753692627\n",
            "Epoch: 3760 Loss D.: 0.6072461605072021\n",
            "Epoch: 3760 Loss G.: 0.8536919951438904\n",
            "Epoch: 3770 Loss D.: 0.5775805115699768\n",
            "Epoch: 3770 Loss G.: 0.8269217014312744\n",
            "Epoch: 3780 Loss D.: 0.6311332583427429\n",
            "Epoch: 3780 Loss G.: 0.76762855052948\n",
            "Epoch: 3790 Loss D.: 0.640225887298584\n",
            "Epoch: 3790 Loss G.: 0.8458867073059082\n",
            "Epoch: 3800 Loss D.: 0.6578137874603271\n",
            "Epoch: 3800 Loss G.: 0.8241792917251587\n",
            "Epoch: 3810 Loss D.: 0.656051516532898\n",
            "Epoch: 3810 Loss G.: 0.809410035610199\n",
            "Epoch: 3820 Loss D.: 0.6195333003997803\n",
            "Epoch: 3820 Loss G.: 0.7927236557006836\n",
            "Epoch: 3830 Loss D.: 0.680902898311615\n",
            "Epoch: 3830 Loss G.: 0.8334184885025024\n",
            "Epoch: 3840 Loss D.: 0.677503228187561\n",
            "Epoch: 3840 Loss G.: 0.9189124703407288\n",
            "Epoch: 3850 Loss D.: 0.6501009464263916\n",
            "Epoch: 3850 Loss G.: 0.7949962019920349\n",
            "Epoch: 3860 Loss D.: 0.601153552532196\n",
            "Epoch: 3860 Loss G.: 0.8803465366363525\n",
            "Epoch: 3870 Loss D.: 0.5619681477546692\n",
            "Epoch: 3870 Loss G.: 0.7812642455101013\n",
            "Epoch: 3880 Loss D.: 0.6656128168106079\n",
            "Epoch: 3880 Loss G.: 0.7874142527580261\n",
            "Epoch: 3890 Loss D.: 0.5872344970703125\n",
            "Epoch: 3890 Loss G.: 0.7917923331260681\n",
            "Epoch: 3900 Loss D.: 0.5771424770355225\n",
            "Epoch: 3900 Loss G.: 0.836858868598938\n",
            "Epoch: 3910 Loss D.: 0.5484583377838135\n",
            "Epoch: 3910 Loss G.: 0.7932611703872681\n",
            "Epoch: 3920 Loss D.: 0.5999906659126282\n",
            "Epoch: 3920 Loss G.: 0.8459320068359375\n",
            "Epoch: 3930 Loss D.: 0.6349926590919495\n",
            "Epoch: 3930 Loss G.: 0.8354974985122681\n",
            "Epoch: 3940 Loss D.: 0.6533984541893005\n",
            "Epoch: 3940 Loss G.: 0.8977862596511841\n",
            "Epoch: 3950 Loss D.: 0.6146903038024902\n",
            "Epoch: 3950 Loss G.: 0.821340799331665\n",
            "Epoch: 3960 Loss D.: 0.5583018660545349\n",
            "Epoch: 3960 Loss G.: 0.8247421979904175\n",
            "Epoch: 3970 Loss D.: 0.5987599492073059\n",
            "Epoch: 3970 Loss G.: 0.9321478009223938\n",
            "Epoch: 3980 Loss D.: 0.6003598570823669\n",
            "Epoch: 3980 Loss G.: 0.9013686776161194\n",
            "Epoch: 3990 Loss D.: 0.6372162103652954\n",
            "Epoch: 3990 Loss G.: 0.8286119103431702\n",
            "Epoch: 4000 Loss D.: 0.6234850287437439\n",
            "Epoch: 4000 Loss G.: 0.9026722311973572\n",
            "Epoch: 4010 Loss D.: 0.6021251678466797\n",
            "Epoch: 4010 Loss G.: 0.8406945466995239\n",
            "Epoch: 4020 Loss D.: 0.6115337610244751\n",
            "Epoch: 4020 Loss G.: 0.8043420910835266\n",
            "Epoch: 4030 Loss D.: 0.6635575294494629\n",
            "Epoch: 4030 Loss G.: 0.8234047293663025\n",
            "Epoch: 4040 Loss D.: 0.6100528240203857\n",
            "Epoch: 4040 Loss G.: 0.8160057067871094\n",
            "Epoch: 4050 Loss D.: 0.609107255935669\n",
            "Epoch: 4050 Loss G.: 0.86292964220047\n",
            "Epoch: 4060 Loss D.: 0.6279783248901367\n",
            "Epoch: 4060 Loss G.: 0.8695222735404968\n",
            "Epoch: 4070 Loss D.: 0.5705319046974182\n",
            "Epoch: 4070 Loss G.: 0.8111280202865601\n",
            "Epoch: 4080 Loss D.: 0.585464358329773\n",
            "Epoch: 4080 Loss G.: 0.9149301052093506\n",
            "Epoch: 4090 Loss D.: 0.5993066430091858\n",
            "Epoch: 4090 Loss G.: 0.8280299305915833\n",
            "Epoch: 4100 Loss D.: 0.5970931649208069\n",
            "Epoch: 4100 Loss G.: 0.7710127234458923\n",
            "Epoch: 4110 Loss D.: 0.6021940112113953\n",
            "Epoch: 4110 Loss G.: 0.7942102551460266\n",
            "Epoch: 4120 Loss D.: 0.7296103239059448\n",
            "Epoch: 4120 Loss G.: 0.925153374671936\n",
            "Epoch: 4130 Loss D.: 0.689437985420227\n",
            "Epoch: 4130 Loss G.: 0.8058921694755554\n",
            "Epoch: 4140 Loss D.: 0.6246822476387024\n",
            "Epoch: 4140 Loss G.: 0.8667392730712891\n",
            "Epoch: 4150 Loss D.: 0.6879197359085083\n",
            "Epoch: 4150 Loss G.: 0.849122941493988\n",
            "Epoch: 4160 Loss D.: 0.6944820880889893\n",
            "Epoch: 4160 Loss G.: 0.8252543210983276\n",
            "Epoch: 4170 Loss D.: 0.5478691458702087\n",
            "Epoch: 4170 Loss G.: 0.8830257654190063\n",
            "Epoch: 4180 Loss D.: 0.6322093605995178\n",
            "Epoch: 4180 Loss G.: 0.8805679678916931\n",
            "Epoch: 4190 Loss D.: 0.6501637697219849\n",
            "Epoch: 4190 Loss G.: 0.8994912505149841\n",
            "Epoch: 4200 Loss D.: 0.6455451250076294\n",
            "Epoch: 4200 Loss G.: 0.7989873886108398\n",
            "Epoch: 4210 Loss D.: 0.6215224266052246\n",
            "Epoch: 4210 Loss G.: 0.7771398425102234\n",
            "Epoch: 4220 Loss D.: 0.6174615621566772\n",
            "Epoch: 4220 Loss G.: 0.8770938515663147\n",
            "Epoch: 4230 Loss D.: 0.5762981176376343\n",
            "Epoch: 4230 Loss G.: 0.8045757412910461\n",
            "Epoch: 4240 Loss D.: 0.6238090395927429\n",
            "Epoch: 4240 Loss G.: 0.8721654415130615\n",
            "Epoch: 4250 Loss D.: 0.6568005681037903\n",
            "Epoch: 4250 Loss G.: 0.7816224694252014\n",
            "Epoch: 4260 Loss D.: 0.583406388759613\n",
            "Epoch: 4260 Loss G.: 0.8052152395248413\n",
            "Epoch: 4270 Loss D.: 0.605976939201355\n",
            "Epoch: 4270 Loss G.: 0.8126459121704102\n",
            "Epoch: 4280 Loss D.: 0.63946133852005\n",
            "Epoch: 4280 Loss G.: 0.8952122926712036\n",
            "Epoch: 4290 Loss D.: 0.6287869811058044\n",
            "Epoch: 4290 Loss G.: 0.8308463096618652\n",
            "Epoch: 4300 Loss D.: 0.6106605529785156\n",
            "Epoch: 4300 Loss G.: 0.782951831817627\n",
            "Epoch: 4310 Loss D.: 0.5687762498855591\n",
            "Epoch: 4310 Loss G.: 0.8292393088340759\n",
            "Epoch: 4320 Loss D.: 0.6909493207931519\n",
            "Epoch: 4320 Loss G.: 0.9146149158477783\n",
            "Epoch: 4330 Loss D.: 0.6333985328674316\n",
            "Epoch: 4330 Loss G.: 0.8443900346755981\n",
            "Epoch: 4340 Loss D.: 0.630524218082428\n",
            "Epoch: 4340 Loss G.: 0.8433356285095215\n",
            "Epoch: 4350 Loss D.: 0.5859386324882507\n",
            "Epoch: 4350 Loss G.: 0.8992815613746643\n",
            "Epoch: 4360 Loss D.: 0.6391558647155762\n",
            "Epoch: 4360 Loss G.: 0.8985850811004639\n",
            "Epoch: 4370 Loss D.: 0.5808037519454956\n",
            "Epoch: 4370 Loss G.: 0.8625168204307556\n",
            "Epoch: 4380 Loss D.: 0.5667633414268494\n",
            "Epoch: 4380 Loss G.: 0.8076735138893127\n",
            "Epoch: 4390 Loss D.: 0.6339172720909119\n",
            "Epoch: 4390 Loss G.: 0.9614406824111938\n",
            "Epoch: 4400 Loss D.: 0.5978968143463135\n",
            "Epoch: 4400 Loss G.: 0.8855779767036438\n",
            "Epoch: 4410 Loss D.: 0.5624546408653259\n",
            "Epoch: 4410 Loss G.: 0.9364946484565735\n",
            "Epoch: 4420 Loss D.: 0.6194230914115906\n",
            "Epoch: 4420 Loss G.: 0.8545939922332764\n",
            "Epoch: 4430 Loss D.: 0.5732690095901489\n",
            "Epoch: 4430 Loss G.: 0.8365881443023682\n",
            "Epoch: 4440 Loss D.: 0.6222863793373108\n",
            "Epoch: 4440 Loss G.: 0.7548218369483948\n",
            "Epoch: 4450 Loss D.: 0.6388188600540161\n",
            "Epoch: 4450 Loss G.: 0.77978515625\n",
            "Epoch: 4460 Loss D.: 0.5881108045578003\n",
            "Epoch: 4460 Loss G.: 0.8402411937713623\n",
            "Epoch: 4470 Loss D.: 0.6042044758796692\n",
            "Epoch: 4470 Loss G.: 0.8664028644561768\n",
            "Epoch: 4480 Loss D.: 0.658348798751831\n",
            "Epoch: 4480 Loss G.: 0.9301968216896057\n",
            "Epoch: 4490 Loss D.: 0.5934613347053528\n",
            "Epoch: 4490 Loss G.: 0.8199319243431091\n",
            "Epoch: 4500 Loss D.: 0.5894642472267151\n",
            "Epoch: 4500 Loss G.: 0.8289027810096741\n",
            "Epoch: 4510 Loss D.: 0.5723782181739807\n",
            "Epoch: 4510 Loss G.: 0.9743510484695435\n",
            "Epoch: 4520 Loss D.: 0.632577657699585\n",
            "Epoch: 4520 Loss G.: 0.8377642631530762\n",
            "Epoch: 4530 Loss D.: 0.6110608577728271\n",
            "Epoch: 4530 Loss G.: 0.9289758205413818\n",
            "Epoch: 4540 Loss D.: 0.6255446076393127\n",
            "Epoch: 4540 Loss G.: 0.8222962021827698\n",
            "Epoch: 4550 Loss D.: 0.6054183840751648\n",
            "Epoch: 4550 Loss G.: 0.9024670124053955\n",
            "Epoch: 4560 Loss D.: 0.5987517237663269\n",
            "Epoch: 4560 Loss G.: 0.8337208032608032\n",
            "Epoch: 4570 Loss D.: 0.7364073395729065\n",
            "Epoch: 4570 Loss G.: 0.8956562876701355\n",
            "Epoch: 4580 Loss D.: 0.6059516668319702\n",
            "Epoch: 4580 Loss G.: 0.8586533069610596\n",
            "Epoch: 4590 Loss D.: 0.5573007464408875\n",
            "Epoch: 4590 Loss G.: 0.9118873476982117\n",
            "Epoch: 4600 Loss D.: 0.6271402835845947\n",
            "Epoch: 4600 Loss G.: 0.8457026481628418\n",
            "Epoch: 4610 Loss D.: 0.6203528642654419\n",
            "Epoch: 4610 Loss G.: 0.8364651203155518\n",
            "Epoch: 4620 Loss D.: 0.6455800533294678\n",
            "Epoch: 4620 Loss G.: 0.8378944993019104\n",
            "Epoch: 4630 Loss D.: 0.6415168642997742\n",
            "Epoch: 4630 Loss G.: 0.8434700965881348\n",
            "Epoch: 4640 Loss D.: 0.6363129019737244\n",
            "Epoch: 4640 Loss G.: 0.8884308338165283\n",
            "Epoch: 4650 Loss D.: 0.6095724701881409\n",
            "Epoch: 4650 Loss G.: 0.8332169055938721\n",
            "Epoch: 4660 Loss D.: 0.6358572244644165\n",
            "Epoch: 4660 Loss G.: 0.8751589059829712\n",
            "Epoch: 4670 Loss D.: 0.6425855159759521\n",
            "Epoch: 4670 Loss G.: 0.7949159741401672\n",
            "Epoch: 4680 Loss D.: 0.6161702871322632\n",
            "Epoch: 4680 Loss G.: 0.875572144985199\n",
            "Epoch: 4690 Loss D.: 0.6191508769989014\n",
            "Epoch: 4690 Loss G.: 0.8243298530578613\n",
            "Epoch: 4700 Loss D.: 0.5631015300750732\n",
            "Epoch: 4700 Loss G.: 0.9164546132087708\n",
            "Epoch: 4710 Loss D.: 0.6602315306663513\n",
            "Epoch: 4710 Loss G.: 0.8621877431869507\n",
            "Epoch: 4720 Loss D.: 0.5594746470451355\n",
            "Epoch: 4720 Loss G.: 0.8221695423126221\n",
            "Epoch: 4730 Loss D.: 0.5788447260856628\n",
            "Epoch: 4730 Loss G.: 0.7777506113052368\n",
            "Epoch: 4740 Loss D.: 0.6039958000183105\n",
            "Epoch: 4740 Loss G.: 0.8494890928268433\n",
            "Epoch: 4750 Loss D.: 0.7881743907928467\n",
            "Epoch: 4750 Loss G.: 0.8264909982681274\n",
            "Epoch: 4760 Loss D.: 0.5622569918632507\n",
            "Epoch: 4760 Loss G.: 0.7859331965446472\n",
            "Epoch: 4770 Loss D.: 0.5887637734413147\n",
            "Epoch: 4770 Loss G.: 0.8841859102249146\n",
            "Epoch: 4780 Loss D.: 0.5635457038879395\n",
            "Epoch: 4780 Loss G.: 0.9039583206176758\n",
            "Epoch: 4790 Loss D.: 0.7663291692733765\n",
            "Epoch: 4790 Loss G.: 0.7980596423149109\n",
            "Epoch: 4800 Loss D.: 0.5829718708992004\n",
            "Epoch: 4800 Loss G.: 0.8708990216255188\n",
            "Epoch: 4810 Loss D.: 0.5953813195228577\n",
            "Epoch: 4810 Loss G.: 0.7892763614654541\n",
            "Epoch: 4820 Loss D.: 0.6403515934944153\n",
            "Epoch: 4820 Loss G.: 0.827765703201294\n",
            "Epoch: 4830 Loss D.: 0.6024512648582458\n",
            "Epoch: 4830 Loss G.: 0.9346374273300171\n",
            "Epoch: 4840 Loss D.: 0.5550073385238647\n",
            "Epoch: 4840 Loss G.: 0.9044148921966553\n",
            "Epoch: 4850 Loss D.: 0.6116113662719727\n",
            "Epoch: 4850 Loss G.: 0.8030788898468018\n",
            "Epoch: 4860 Loss D.: 0.6193811297416687\n",
            "Epoch: 4860 Loss G.: 0.8784281015396118\n",
            "Epoch: 4870 Loss D.: 0.60611492395401\n",
            "Epoch: 4870 Loss G.: 0.8689757585525513\n",
            "Epoch: 4880 Loss D.: 0.5821910500526428\n",
            "Epoch: 4880 Loss G.: 0.8785399794578552\n",
            "Epoch: 4890 Loss D.: 0.6257964968681335\n",
            "Epoch: 4890 Loss G.: 0.8119185566902161\n",
            "Epoch: 4900 Loss D.: 0.5863421559333801\n",
            "Epoch: 4900 Loss G.: 0.9464768767356873\n",
            "Epoch: 4910 Loss D.: 0.563174843788147\n",
            "Epoch: 4910 Loss G.: 0.8666011691093445\n",
            "Epoch: 4920 Loss D.: 0.5661001205444336\n",
            "Epoch: 4920 Loss G.: 0.8145455121994019\n",
            "Epoch: 4930 Loss D.: 0.5630616545677185\n",
            "Epoch: 4930 Loss G.: 0.8260244131088257\n",
            "Epoch: 4940 Loss D.: 0.6612962484359741\n",
            "Epoch: 4940 Loss G.: 0.9078998565673828\n",
            "Epoch: 4950 Loss D.: 0.6290707588195801\n",
            "Epoch: 4950 Loss G.: 0.8905271887779236\n",
            "Epoch: 4960 Loss D.: 0.6146642565727234\n",
            "Epoch: 4960 Loss G.: 0.8422733545303345\n",
            "Epoch: 4970 Loss D.: 0.6579951047897339\n",
            "Epoch: 4970 Loss G.: 0.8611679673194885\n",
            "Epoch: 4980 Loss D.: 0.5972485542297363\n",
            "Epoch: 4980 Loss G.: 0.7709015607833862\n",
            "Epoch: 4990 Loss D.: 0.5641454458236694\n",
            "Epoch: 4990 Loss G.: 0.8222848773002625\n",
            "Epoch: 5000 Loss D.: 0.5781733393669128\n",
            "Epoch: 5000 Loss G.: 0.8930798768997192\n",
            "Epoch: 5010 Loss D.: 0.6369235515594482\n",
            "Epoch: 5010 Loss G.: 0.8744551539421082\n",
            "Epoch: 5020 Loss D.: 0.6746457815170288\n",
            "Epoch: 5020 Loss G.: 0.8364226222038269\n",
            "Epoch: 5030 Loss D.: 0.6468446254730225\n",
            "Epoch: 5030 Loss G.: 0.8333112597465515\n",
            "Epoch: 5040 Loss D.: 0.7422252893447876\n",
            "Epoch: 5040 Loss G.: 0.944210410118103\n",
            "Epoch: 5050 Loss D.: 0.5961055159568787\n",
            "Epoch: 5050 Loss G.: 0.91377192735672\n",
            "Epoch: 5060 Loss D.: 0.5351699590682983\n",
            "Epoch: 5060 Loss G.: 0.8587249517440796\n",
            "Epoch: 5070 Loss D.: 0.5714935660362244\n",
            "Epoch: 5070 Loss G.: 0.8127689361572266\n",
            "Epoch: 5080 Loss D.: 0.6248246431350708\n",
            "Epoch: 5080 Loss G.: 0.9903591871261597\n",
            "Epoch: 5090 Loss D.: 0.6100397109985352\n",
            "Epoch: 5090 Loss G.: 0.8034909963607788\n",
            "Epoch: 5100 Loss D.: 0.5796410441398621\n",
            "Epoch: 5100 Loss G.: 0.9504634737968445\n",
            "Epoch: 5110 Loss D.: 0.6326727867126465\n",
            "Epoch: 5110 Loss G.: 0.8544307947158813\n",
            "Epoch: 5120 Loss D.: 0.545892059803009\n",
            "Epoch: 5120 Loss G.: 0.7950358986854553\n",
            "Epoch: 5130 Loss D.: 0.6206591129302979\n",
            "Epoch: 5130 Loss G.: 0.8885550498962402\n",
            "Epoch: 5140 Loss D.: 0.6448113322257996\n",
            "Epoch: 5140 Loss G.: 0.801540732383728\n",
            "Epoch: 5150 Loss D.: 0.6201245188713074\n",
            "Epoch: 5150 Loss G.: 0.8834680318832397\n",
            "Epoch: 5160 Loss D.: 0.615709125995636\n",
            "Epoch: 5160 Loss G.: 0.8600938320159912\n",
            "Epoch: 5170 Loss D.: 0.5126581192016602\n",
            "Epoch: 5170 Loss G.: 0.8823870420455933\n",
            "Epoch: 5180 Loss D.: 0.5595631003379822\n",
            "Epoch: 5180 Loss G.: 0.911275327205658\n",
            "Epoch: 5190 Loss D.: 0.5671586394309998\n",
            "Epoch: 5190 Loss G.: 0.9014005064964294\n",
            "Epoch: 5200 Loss D.: 0.5983545780181885\n",
            "Epoch: 5200 Loss G.: 0.8803665637969971\n",
            "Epoch: 5210 Loss D.: 0.6298232674598694\n",
            "Epoch: 5210 Loss G.: 0.8756579160690308\n",
            "Epoch: 5220 Loss D.: 0.6114234328269958\n",
            "Epoch: 5220 Loss G.: 0.8194150924682617\n",
            "Epoch: 5230 Loss D.: 0.5820367932319641\n",
            "Epoch: 5230 Loss G.: 0.8279197216033936\n",
            "Epoch: 5240 Loss D.: 0.5669182538986206\n",
            "Epoch: 5240 Loss G.: 0.8703069686889648\n",
            "Epoch: 5250 Loss D.: 0.6305193305015564\n",
            "Epoch: 5250 Loss G.: 0.904395580291748\n",
            "Epoch: 5260 Loss D.: 0.6309574842453003\n",
            "Epoch: 5260 Loss G.: 0.7885569334030151\n",
            "Epoch: 5270 Loss D.: 0.625116765499115\n",
            "Epoch: 5270 Loss G.: 0.8088310956954956\n",
            "Epoch: 5280 Loss D.: 0.6885049343109131\n",
            "Epoch: 5280 Loss G.: 0.8145766258239746\n",
            "Epoch: 5290 Loss D.: 0.5849103927612305\n",
            "Epoch: 5290 Loss G.: 0.8295356035232544\n",
            "Epoch: 5300 Loss D.: 0.633874237537384\n",
            "Epoch: 5300 Loss G.: 0.987856388092041\n",
            "Epoch: 5310 Loss D.: 0.6716447472572327\n",
            "Epoch: 5310 Loss G.: 0.8652769327163696\n",
            "Epoch: 5320 Loss D.: 0.6177829504013062\n",
            "Epoch: 5320 Loss G.: 0.8250598907470703\n",
            "Epoch: 5330 Loss D.: 0.6021984815597534\n",
            "Epoch: 5330 Loss G.: 0.8134300112724304\n",
            "Epoch: 5340 Loss D.: 0.5893190503120422\n",
            "Epoch: 5340 Loss G.: 0.86725914478302\n",
            "Epoch: 5350 Loss D.: 0.6118245124816895\n",
            "Epoch: 5350 Loss G.: 0.7826758027076721\n",
            "Epoch: 5360 Loss D.: 0.5601405501365662\n",
            "Epoch: 5360 Loss G.: 0.827441930770874\n",
            "Epoch: 5370 Loss D.: 0.5797001719474792\n",
            "Epoch: 5370 Loss G.: 0.8015631437301636\n",
            "Epoch: 5380 Loss D.: 0.6235135197639465\n",
            "Epoch: 5380 Loss G.: 0.8117871284484863\n",
            "Epoch: 5390 Loss D.: 0.6397584676742554\n",
            "Epoch: 5390 Loss G.: 0.8984088897705078\n",
            "Epoch: 5400 Loss D.: 0.6178446412086487\n",
            "Epoch: 5400 Loss G.: 0.8480884432792664\n",
            "Epoch: 5410 Loss D.: 0.595034122467041\n",
            "Epoch: 5410 Loss G.: 0.8516409397125244\n",
            "Epoch: 5420 Loss D.: 0.6157835721969604\n",
            "Epoch: 5420 Loss G.: 0.8742817044258118\n",
            "Epoch: 5430 Loss D.: 0.6431041359901428\n",
            "Epoch: 5430 Loss G.: 0.8380595445632935\n",
            "Epoch: 5440 Loss D.: 0.6258786916732788\n",
            "Epoch: 5440 Loss G.: 0.8579062223434448\n",
            "Epoch: 5450 Loss D.: 0.6046577095985413\n",
            "Epoch: 5450 Loss G.: 0.8976651430130005\n",
            "Epoch: 5460 Loss D.: 0.5813794732093811\n",
            "Epoch: 5460 Loss G.: 0.8860613107681274\n",
            "Epoch: 5470 Loss D.: 0.5605873465538025\n",
            "Epoch: 5470 Loss G.: 0.883248507976532\n",
            "Epoch: 5480 Loss D.: 0.5855493545532227\n",
            "Epoch: 5480 Loss G.: 0.8503215909004211\n",
            "Epoch: 5490 Loss D.: 0.6128739714622498\n",
            "Epoch: 5490 Loss G.: 0.8458092212677002\n",
            "Epoch: 5500 Loss D.: 0.593215823173523\n",
            "Epoch: 5500 Loss G.: 0.8100427389144897\n",
            "Epoch: 5510 Loss D.: 0.5607929229736328\n",
            "Epoch: 5510 Loss G.: 0.9159448742866516\n",
            "Epoch: 5520 Loss D.: 0.6336017847061157\n",
            "Epoch: 5520 Loss G.: 0.934079110622406\n",
            "Epoch: 5530 Loss D.: 0.6496791243553162\n",
            "Epoch: 5530 Loss G.: 0.8215097784996033\n",
            "Epoch: 5540 Loss D.: 0.6026091575622559\n",
            "Epoch: 5540 Loss G.: 0.8223545551300049\n",
            "Epoch: 5550 Loss D.: 0.6037439107894897\n",
            "Epoch: 5550 Loss G.: 0.8239994645118713\n",
            "Epoch: 5560 Loss D.: 0.567891538143158\n",
            "Epoch: 5560 Loss G.: 0.9073827266693115\n",
            "Epoch: 5570 Loss D.: 0.5896418690681458\n",
            "Epoch: 5570 Loss G.: 0.9238244891166687\n",
            "Epoch: 5580 Loss D.: 0.5241544246673584\n",
            "Epoch: 5580 Loss G.: 0.9730728268623352\n",
            "Epoch: 5590 Loss D.: 0.5978858470916748\n",
            "Epoch: 5590 Loss G.: 0.881233274936676\n",
            "Epoch: 5600 Loss D.: 0.6351081728935242\n",
            "Epoch: 5600 Loss G.: 0.8405425548553467\n",
            "Epoch: 5610 Loss D.: 0.5989844799041748\n",
            "Epoch: 5610 Loss G.: 0.9060702919960022\n",
            "Epoch: 5620 Loss D.: 0.6199612021446228\n",
            "Epoch: 5620 Loss G.: 0.9689594507217407\n",
            "Epoch: 5630 Loss D.: 0.573556661605835\n",
            "Epoch: 5630 Loss G.: 0.8116616010665894\n",
            "Epoch: 5640 Loss D.: 0.6470074653625488\n",
            "Epoch: 5640 Loss G.: 0.850053608417511\n",
            "Epoch: 5650 Loss D.: 0.5872133374214172\n",
            "Epoch: 5650 Loss G.: 0.843618631362915\n",
            "Epoch: 5660 Loss D.: 0.627855122089386\n",
            "Epoch: 5660 Loss G.: 0.9426282644271851\n",
            "Epoch: 5670 Loss D.: 0.5881876349449158\n",
            "Epoch: 5670 Loss G.: 0.7789303064346313\n",
            "Epoch: 5680 Loss D.: 0.617536723613739\n",
            "Epoch: 5680 Loss G.: 0.8718727827072144\n",
            "Epoch: 5690 Loss D.: 0.5653569102287292\n",
            "Epoch: 5690 Loss G.: 0.8282615542411804\n",
            "Epoch: 5700 Loss D.: 0.5861772298812866\n",
            "Epoch: 5700 Loss G.: 0.852231502532959\n",
            "Epoch: 5710 Loss D.: 0.5705300569534302\n",
            "Epoch: 5710 Loss G.: 0.8796597719192505\n",
            "Epoch: 5720 Loss D.: 0.5752269625663757\n",
            "Epoch: 5720 Loss G.: 0.8586711883544922\n",
            "Epoch: 5730 Loss D.: 0.6503806114196777\n",
            "Epoch: 5730 Loss G.: 0.8476958870887756\n",
            "Epoch: 5740 Loss D.: 0.5493887662887573\n",
            "Epoch: 5740 Loss G.: 0.8178962469100952\n",
            "Epoch: 5750 Loss D.: 0.608536958694458\n",
            "Epoch: 5750 Loss G.: 0.8875908255577087\n",
            "Epoch: 5760 Loss D.: 0.5849127769470215\n",
            "Epoch: 5760 Loss G.: 0.884390115737915\n",
            "Epoch: 5770 Loss D.: 0.5776263475418091\n",
            "Epoch: 5770 Loss G.: 0.869509220123291\n",
            "Epoch: 5780 Loss D.: 0.6010785698890686\n",
            "Epoch: 5780 Loss G.: 0.8300209045410156\n",
            "Epoch: 5790 Loss D.: 0.6258692741394043\n",
            "Epoch: 5790 Loss G.: 0.8810336589813232\n",
            "Epoch: 5800 Loss D.: 0.6074835062026978\n",
            "Epoch: 5800 Loss G.: 0.9144149422645569\n",
            "Epoch: 5810 Loss D.: 0.5891842246055603\n",
            "Epoch: 5810 Loss G.: 0.9347968101501465\n",
            "Epoch: 5820 Loss D.: 0.5750302076339722\n",
            "Epoch: 5820 Loss G.: 0.9562574625015259\n",
            "Epoch: 5830 Loss D.: 0.5818268656730652\n",
            "Epoch: 5830 Loss G.: 0.8800674080848694\n",
            "Epoch: 5840 Loss D.: 0.607282817363739\n",
            "Epoch: 5840 Loss G.: 0.9186984896659851\n",
            "Epoch: 5850 Loss D.: 0.5927102565765381\n",
            "Epoch: 5850 Loss G.: 0.9021416902542114\n",
            "Epoch: 5860 Loss D.: 0.609008252620697\n",
            "Epoch: 5860 Loss G.: 0.8481996059417725\n",
            "Epoch: 5870 Loss D.: 0.5456231832504272\n",
            "Epoch: 5870 Loss G.: 0.8855788111686707\n",
            "Epoch: 5880 Loss D.: 0.5860573053359985\n",
            "Epoch: 5880 Loss G.: 0.8120339512825012\n",
            "Epoch: 5890 Loss D.: 0.5815587043762207\n",
            "Epoch: 5890 Loss G.: 0.873238205909729\n",
            "Epoch: 5900 Loss D.: 0.5995023250579834\n",
            "Epoch: 5900 Loss G.: 0.8420535326004028\n",
            "Epoch: 5910 Loss D.: 0.6788160800933838\n",
            "Epoch: 5910 Loss G.: 0.8290550708770752\n",
            "Epoch: 5920 Loss D.: 0.6062750220298767\n",
            "Epoch: 5920 Loss G.: 0.8720625638961792\n",
            "Epoch: 5930 Loss D.: 0.6268284916877747\n",
            "Epoch: 5930 Loss G.: 0.8237519264221191\n",
            "Epoch: 5940 Loss D.: 0.6220288872718811\n",
            "Epoch: 5940 Loss G.: 0.9822921752929688\n",
            "Epoch: 5950 Loss D.: 0.5798670649528503\n",
            "Epoch: 5950 Loss G.: 0.847694993019104\n",
            "Epoch: 5960 Loss D.: 0.7362696528434753\n",
            "Epoch: 5960 Loss G.: 0.8051596283912659\n",
            "Epoch: 5970 Loss D.: 0.599757194519043\n",
            "Epoch: 5970 Loss G.: 1.0088348388671875\n",
            "Epoch: 5980 Loss D.: 0.5839147567749023\n",
            "Epoch: 5980 Loss G.: 0.8321625590324402\n",
            "Epoch: 5990 Loss D.: 0.6330978870391846\n",
            "Epoch: 5990 Loss G.: 0.8387636542320251\n",
            "Epoch: 6000 Loss D.: 0.6302290558815002\n",
            "Epoch: 6000 Loss G.: 0.892460286617279\n",
            "Epoch: 6010 Loss D.: 0.6167446374893188\n",
            "Epoch: 6010 Loss G.: 0.8348554372787476\n",
            "Epoch: 6020 Loss D.: 0.5905224680900574\n",
            "Epoch: 6020 Loss G.: 0.9133358597755432\n",
            "Epoch: 6030 Loss D.: 0.6149235367774963\n",
            "Epoch: 6030 Loss G.: 0.880106508731842\n",
            "Epoch: 6040 Loss D.: 0.6007720828056335\n",
            "Epoch: 6040 Loss G.: 0.8049917817115784\n",
            "Epoch: 6050 Loss D.: 0.645201563835144\n",
            "Epoch: 6050 Loss G.: 0.8546063303947449\n",
            "Epoch: 6060 Loss D.: 0.6406351923942566\n",
            "Epoch: 6060 Loss G.: 0.8632252216339111\n",
            "Epoch: 6070 Loss D.: 0.5816746950149536\n",
            "Epoch: 6070 Loss G.: 0.8372725248336792\n",
            "Epoch: 6080 Loss D.: 0.5792394876480103\n",
            "Epoch: 6080 Loss G.: 0.8688730597496033\n",
            "Epoch: 6090 Loss D.: 0.6113446950912476\n",
            "Epoch: 6090 Loss G.: 0.801151692867279\n",
            "Epoch: 6100 Loss D.: 0.5833706855773926\n",
            "Epoch: 6100 Loss G.: 0.8510481119155884\n",
            "Epoch: 6110 Loss D.: 0.6297280788421631\n",
            "Epoch: 6110 Loss G.: 0.8743611574172974\n",
            "Epoch: 6120 Loss D.: 0.5526761412620544\n",
            "Epoch: 6120 Loss G.: 0.9183634519577026\n",
            "Epoch: 6130 Loss D.: 0.5900729298591614\n",
            "Epoch: 6130 Loss G.: 0.8939886093139648\n",
            "Epoch: 6140 Loss D.: 0.5444408655166626\n",
            "Epoch: 6140 Loss G.: 0.9190800189971924\n",
            "Epoch: 6150 Loss D.: 0.5534113645553589\n",
            "Epoch: 6150 Loss G.: 1.0067243576049805\n",
            "Epoch: 6160 Loss D.: 0.6013492941856384\n",
            "Epoch: 6160 Loss G.: 0.8693768382072449\n",
            "Epoch: 6170 Loss D.: 0.5945684909820557\n",
            "Epoch: 6170 Loss G.: 0.9055759310722351\n",
            "Epoch: 6180 Loss D.: 0.5982286930084229\n",
            "Epoch: 6180 Loss G.: 0.9965036511421204\n",
            "Epoch: 6190 Loss D.: 0.6075049638748169\n",
            "Epoch: 6190 Loss G.: 0.8378186225891113\n",
            "Epoch: 6200 Loss D.: 0.6035900115966797\n",
            "Epoch: 6200 Loss G.: 0.8192064762115479\n",
            "Epoch: 6210 Loss D.: 0.6197754740715027\n",
            "Epoch: 6210 Loss G.: 0.8391602635383606\n",
            "Epoch: 6220 Loss D.: 0.5991808176040649\n",
            "Epoch: 6220 Loss G.: 0.8484283685684204\n",
            "Epoch: 6230 Loss D.: 0.5756379961967468\n",
            "Epoch: 6230 Loss G.: 0.8691372275352478\n",
            "Epoch: 6240 Loss D.: 0.6072495579719543\n",
            "Epoch: 6240 Loss G.: 0.9994128942489624\n",
            "Epoch: 6250 Loss D.: 0.5833580493927002\n",
            "Epoch: 6250 Loss G.: 0.9039798378944397\n",
            "Epoch: 6260 Loss D.: 0.6004310250282288\n",
            "Epoch: 6260 Loss G.: 0.8605204224586487\n",
            "Epoch: 6270 Loss D.: 0.6179898381233215\n",
            "Epoch: 6270 Loss G.: 0.8344094753265381\n",
            "Epoch: 6280 Loss D.: 0.5518896579742432\n",
            "Epoch: 6280 Loss G.: 0.9517062902450562\n",
            "Epoch: 6290 Loss D.: 0.5345896482467651\n",
            "Epoch: 6290 Loss G.: 0.850798487663269\n",
            "Epoch: 6300 Loss D.: 0.642816960811615\n",
            "Epoch: 6300 Loss G.: 0.8102391362190247\n",
            "Epoch: 6310 Loss D.: 0.6941056847572327\n",
            "Epoch: 6310 Loss G.: 0.9872457385063171\n",
            "Epoch: 6320 Loss D.: 0.5999121069908142\n",
            "Epoch: 6320 Loss G.: 0.8925438523292542\n",
            "Epoch: 6330 Loss D.: 0.6598011255264282\n",
            "Epoch: 6330 Loss G.: 1.0188472270965576\n",
            "Epoch: 6340 Loss D.: 0.588707447052002\n",
            "Epoch: 6340 Loss G.: 0.9312092065811157\n",
            "Epoch: 6350 Loss D.: 0.700226902961731\n",
            "Epoch: 6350 Loss G.: 0.8356871604919434\n",
            "Epoch: 6360 Loss D.: 0.6863281726837158\n",
            "Epoch: 6360 Loss G.: 0.8412454128265381\n",
            "Epoch: 6370 Loss D.: 0.5657227635383606\n",
            "Epoch: 6370 Loss G.: 0.8606969714164734\n",
            "Epoch: 6380 Loss D.: 0.5899471044540405\n",
            "Epoch: 6380 Loss G.: 1.1049377918243408\n",
            "Epoch: 6390 Loss D.: 0.5923328995704651\n",
            "Epoch: 6390 Loss G.: 0.9552017450332642\n",
            "Epoch: 6400 Loss D.: 0.545352578163147\n",
            "Epoch: 6400 Loss G.: 0.9203100204467773\n",
            "Epoch: 6410 Loss D.: 0.611497163772583\n",
            "Epoch: 6410 Loss G.: 0.8892257213592529\n",
            "Epoch: 6420 Loss D.: 0.6062141060829163\n",
            "Epoch: 6420 Loss G.: 0.8199323415756226\n",
            "Epoch: 6430 Loss D.: 0.5885745882987976\n",
            "Epoch: 6430 Loss G.: 0.8393180966377258\n",
            "Epoch: 6440 Loss D.: 0.5681959986686707\n",
            "Epoch: 6440 Loss G.: 0.9358015656471252\n",
            "Epoch: 6450 Loss D.: 0.689869225025177\n",
            "Epoch: 6450 Loss G.: 0.8417540192604065\n",
            "Epoch: 6460 Loss D.: 0.553484320640564\n",
            "Epoch: 6460 Loss G.: 0.8588401675224304\n",
            "Epoch: 6470 Loss D.: 0.6024312973022461\n",
            "Epoch: 6470 Loss G.: 0.8109023571014404\n",
            "Epoch: 6480 Loss D.: 0.6184550523757935\n",
            "Epoch: 6480 Loss G.: 0.89087975025177\n",
            "Epoch: 6490 Loss D.: 0.552699863910675\n",
            "Epoch: 6490 Loss G.: 0.8388627171516418\n",
            "Epoch: 6500 Loss D.: 0.565249502658844\n",
            "Epoch: 6500 Loss G.: 0.9863994717597961\n",
            "Epoch: 6510 Loss D.: 0.6485735177993774\n",
            "Epoch: 6510 Loss G.: 0.8796276450157166\n",
            "Epoch: 6520 Loss D.: 0.5605227947235107\n",
            "Epoch: 6520 Loss G.: 0.8961899280548096\n",
            "Epoch: 6530 Loss D.: 0.5906069278717041\n",
            "Epoch: 6530 Loss G.: 0.8643268346786499\n",
            "Epoch: 6540 Loss D.: 0.6117169857025146\n",
            "Epoch: 6540 Loss G.: 0.9089102745056152\n",
            "Epoch: 6550 Loss D.: 0.569679319858551\n",
            "Epoch: 6550 Loss G.: 0.9030324220657349\n",
            "Epoch: 6560 Loss D.: 0.6044036746025085\n",
            "Epoch: 6560 Loss G.: 0.8436934947967529\n",
            "Epoch: 6570 Loss D.: 0.5971993803977966\n",
            "Epoch: 6570 Loss G.: 0.8812140226364136\n",
            "Epoch: 6580 Loss D.: 0.6496434211730957\n",
            "Epoch: 6580 Loss G.: 0.9119738340377808\n",
            "Epoch: 6590 Loss D.: 0.5526994466781616\n",
            "Epoch: 6590 Loss G.: 0.8682764768600464\n",
            "Epoch: 6600 Loss D.: 0.680871844291687\n",
            "Epoch: 6600 Loss G.: 0.8459627628326416\n",
            "Epoch: 6610 Loss D.: 0.5402331948280334\n",
            "Epoch: 6610 Loss G.: 0.9315727949142456\n",
            "Epoch: 6620 Loss D.: 0.6199926137924194\n",
            "Epoch: 6620 Loss G.: 0.9022529125213623\n",
            "Epoch: 6630 Loss D.: 0.5930798053741455\n",
            "Epoch: 6630 Loss G.: 0.8393694162368774\n",
            "Epoch: 6640 Loss D.: 0.6367747783660889\n",
            "Epoch: 6640 Loss G.: 0.8251832127571106\n",
            "Epoch: 6650 Loss D.: 0.5816037058830261\n",
            "Epoch: 6650 Loss G.: 0.8761805295944214\n",
            "Epoch: 6660 Loss D.: 0.5583492517471313\n",
            "Epoch: 6660 Loss G.: 0.8740742802619934\n",
            "Epoch: 6670 Loss D.: 0.5365515947341919\n",
            "Epoch: 6670 Loss G.: 0.8402799963951111\n",
            "Epoch: 6680 Loss D.: 0.5332430601119995\n",
            "Epoch: 6680 Loss G.: 0.8693041801452637\n",
            "Epoch: 6690 Loss D.: 0.6198698878288269\n",
            "Epoch: 6690 Loss G.: 0.8761135935783386\n",
            "Epoch: 6700 Loss D.: 0.5924191474914551\n",
            "Epoch: 6700 Loss G.: 0.8422343730926514\n",
            "Epoch: 6710 Loss D.: 0.581316351890564\n",
            "Epoch: 6710 Loss G.: 0.8309451341629028\n",
            "Epoch: 6720 Loss D.: 0.5701723694801331\n",
            "Epoch: 6720 Loss G.: 0.8474095463752747\n",
            "Epoch: 6730 Loss D.: 0.6200990676879883\n",
            "Epoch: 6730 Loss G.: 0.8745816946029663\n",
            "Epoch: 6740 Loss D.: 0.6082861423492432\n",
            "Epoch: 6740 Loss G.: 0.9472202658653259\n",
            "Epoch: 6750 Loss D.: 0.6124154329299927\n",
            "Epoch: 6750 Loss G.: 0.9479576945304871\n",
            "Epoch: 6760 Loss D.: 0.5515104532241821\n",
            "Epoch: 6760 Loss G.: 0.847274661064148\n",
            "Epoch: 6770 Loss D.: 0.5153552293777466\n",
            "Epoch: 6770 Loss G.: 0.9564039707183838\n",
            "Epoch: 6780 Loss D.: 0.6379402279853821\n",
            "Epoch: 6780 Loss G.: 0.9017110466957092\n",
            "Epoch: 6790 Loss D.: 0.6094456315040588\n",
            "Epoch: 6790 Loss G.: 0.8225789666175842\n",
            "Epoch: 6800 Loss D.: 0.6020642518997192\n",
            "Epoch: 6800 Loss G.: 0.8605154156684875\n",
            "Epoch: 6810 Loss D.: 0.6072031855583191\n",
            "Epoch: 6810 Loss G.: 0.8675534725189209\n",
            "Epoch: 6820 Loss D.: 0.668691098690033\n",
            "Epoch: 6820 Loss G.: 0.836241602897644\n",
            "Epoch: 6830 Loss D.: 0.6214776039123535\n",
            "Epoch: 6830 Loss G.: 0.884048342704773\n",
            "Epoch: 6840 Loss D.: 0.5435124635696411\n",
            "Epoch: 6840 Loss G.: 0.8320646286010742\n",
            "Epoch: 6850 Loss D.: 0.538036048412323\n",
            "Epoch: 6850 Loss G.: 0.8501445651054382\n",
            "Epoch: 6860 Loss D.: 0.5490983724594116\n",
            "Epoch: 6860 Loss G.: 0.9092748165130615\n",
            "Epoch: 6870 Loss D.: 0.6671164035797119\n",
            "Epoch: 6870 Loss G.: 0.864935040473938\n",
            "Epoch: 6880 Loss D.: 0.6491008400917053\n",
            "Epoch: 6880 Loss G.: 0.8666960597038269\n",
            "Epoch: 6890 Loss D.: 0.5829330682754517\n",
            "Epoch: 6890 Loss G.: 0.8925788402557373\n",
            "Epoch: 6900 Loss D.: 0.6350026726722717\n",
            "Epoch: 6900 Loss G.: 0.8454588651657104\n",
            "Epoch: 6910 Loss D.: 0.5839808583259583\n",
            "Epoch: 6910 Loss G.: 0.8362820148468018\n",
            "Epoch: 6920 Loss D.: 0.5630425810813904\n",
            "Epoch: 6920 Loss G.: 0.8454184532165527\n",
            "Epoch: 6930 Loss D.: 0.6256813406944275\n",
            "Epoch: 6930 Loss G.: 0.8547764420509338\n",
            "Epoch: 6940 Loss D.: 0.6412751078605652\n",
            "Epoch: 6940 Loss G.: 0.8696311116218567\n",
            "Epoch: 6950 Loss D.: 0.6117970943450928\n",
            "Epoch: 6950 Loss G.: 0.8230127096176147\n",
            "Epoch: 6960 Loss D.: 0.6604949235916138\n",
            "Epoch: 6960 Loss G.: 0.8319676518440247\n",
            "Epoch: 6970 Loss D.: 0.5604915618896484\n",
            "Epoch: 6970 Loss G.: 0.9191397428512573\n",
            "Epoch: 6980 Loss D.: 0.572666585445404\n",
            "Epoch: 6980 Loss G.: 0.9809937477111816\n",
            "Epoch: 6990 Loss D.: 0.5928528904914856\n",
            "Epoch: 6990 Loss G.: 0.8293650150299072\n",
            "Epoch: 7000 Loss D.: 0.5577433705329895\n",
            "Epoch: 7000 Loss G.: 0.9454466104507446\n",
            "Epoch: 7010 Loss D.: 0.6034333109855652\n",
            "Epoch: 7010 Loss G.: 0.8031746745109558\n",
            "Epoch: 7020 Loss D.: 0.6505727767944336\n",
            "Epoch: 7020 Loss G.: 0.8602185249328613\n",
            "Epoch: 7030 Loss D.: 0.6044920086860657\n",
            "Epoch: 7030 Loss G.: 0.804625391960144\n",
            "Epoch: 7040 Loss D.: 0.6311460137367249\n",
            "Epoch: 7040 Loss G.: 0.8865640163421631\n",
            "Epoch: 7050 Loss D.: 0.5798466801643372\n",
            "Epoch: 7050 Loss G.: 0.8296382427215576\n",
            "Epoch: 7060 Loss D.: 0.6809853911399841\n",
            "Epoch: 7060 Loss G.: 0.8397359251976013\n",
            "Epoch: 7070 Loss D.: 0.5460266470909119\n",
            "Epoch: 7070 Loss G.: 0.8542852997779846\n",
            "Epoch: 7080 Loss D.: 0.600697934627533\n",
            "Epoch: 7080 Loss G.: 0.9252110719680786\n",
            "Epoch: 7090 Loss D.: 0.5932409167289734\n",
            "Epoch: 7090 Loss G.: 0.9339262843132019\n",
            "Epoch: 7100 Loss D.: 0.5661077499389648\n",
            "Epoch: 7100 Loss G.: 0.94114750623703\n",
            "Epoch: 7110 Loss D.: 0.5660157203674316\n",
            "Epoch: 7110 Loss G.: 0.8294708728790283\n",
            "Epoch: 7120 Loss D.: 0.643932580947876\n",
            "Epoch: 7120 Loss G.: 0.852421224117279\n",
            "Epoch: 7130 Loss D.: 0.5747368931770325\n",
            "Epoch: 7130 Loss G.: 0.8765432834625244\n",
            "Epoch: 7140 Loss D.: 0.6352540254592896\n",
            "Epoch: 7140 Loss G.: 0.8547045588493347\n",
            "Epoch: 7150 Loss D.: 0.5681636333465576\n",
            "Epoch: 7150 Loss G.: 0.8275768160820007\n",
            "Epoch: 7160 Loss D.: 0.5897307395935059\n",
            "Epoch: 7160 Loss G.: 0.8399966955184937\n",
            "Epoch: 7170 Loss D.: 0.612493097782135\n",
            "Epoch: 7170 Loss G.: 0.9677079916000366\n",
            "Epoch: 7180 Loss D.: 0.6014758944511414\n",
            "Epoch: 7180 Loss G.: 0.7779124975204468\n",
            "Epoch: 7190 Loss D.: 0.5961945652961731\n",
            "Epoch: 7190 Loss G.: 0.8733686208724976\n",
            "Epoch: 7200 Loss D.: 0.6396298408508301\n",
            "Epoch: 7200 Loss G.: 0.857559323310852\n",
            "Epoch: 7210 Loss D.: 0.5607873201370239\n",
            "Epoch: 7210 Loss G.: 0.8561351895332336\n",
            "Epoch: 7220 Loss D.: 0.6514084339141846\n",
            "Epoch: 7220 Loss G.: 0.8434972763061523\n",
            "Epoch: 7230 Loss D.: 0.6191825866699219\n",
            "Epoch: 7230 Loss G.: 0.855124294757843\n",
            "Epoch: 7240 Loss D.: 0.5827723741531372\n",
            "Epoch: 7240 Loss G.: 0.8575604557991028\n",
            "Epoch: 7250 Loss D.: 0.6555262207984924\n",
            "Epoch: 7250 Loss G.: 0.8281621932983398\n",
            "Epoch: 7260 Loss D.: 0.590705156326294\n",
            "Epoch: 7260 Loss G.: 0.8749266862869263\n",
            "Epoch: 7270 Loss D.: 0.6446828246116638\n",
            "Epoch: 7270 Loss G.: 0.8843412399291992\n",
            "Epoch: 7280 Loss D.: 0.5922518372535706\n",
            "Epoch: 7280 Loss G.: 0.8655363321304321\n",
            "Epoch: 7290 Loss D.: 0.588983416557312\n",
            "Epoch: 7290 Loss G.: 0.914419949054718\n",
            "Epoch: 7300 Loss D.: 0.5819833874702454\n",
            "Epoch: 7300 Loss G.: 0.9372899532318115\n",
            "Epoch: 7310 Loss D.: 0.5802101492881775\n",
            "Epoch: 7310 Loss G.: 0.958046019077301\n",
            "Epoch: 7320 Loss D.: 0.6158238649368286\n",
            "Epoch: 7320 Loss G.: 0.8675751686096191\n",
            "Epoch: 7330 Loss D.: 0.7041680812835693\n",
            "Epoch: 7330 Loss G.: 0.8695389032363892\n",
            "Epoch: 7340 Loss D.: 0.5992368459701538\n",
            "Epoch: 7340 Loss G.: 0.8541626930236816\n",
            "Epoch: 7350 Loss D.: 0.5634041428565979\n",
            "Epoch: 7350 Loss G.: 0.8551095128059387\n",
            "Epoch: 7360 Loss D.: 0.5922592878341675\n",
            "Epoch: 7360 Loss G.: 0.856740415096283\n",
            "Epoch: 7370 Loss D.: 0.6136216521263123\n",
            "Epoch: 7370 Loss G.: 0.9185421466827393\n",
            "Epoch: 7380 Loss D.: 0.5561196208000183\n",
            "Epoch: 7380 Loss G.: 0.8226723670959473\n",
            "Epoch: 7390 Loss D.: 0.5815141797065735\n",
            "Epoch: 7390 Loss G.: 0.8913483619689941\n",
            "Epoch: 7400 Loss D.: 0.6457514762878418\n",
            "Epoch: 7400 Loss G.: 0.8661373257637024\n",
            "Epoch: 7410 Loss D.: 0.5838172435760498\n",
            "Epoch: 7410 Loss G.: 0.8539086580276489\n",
            "Epoch: 7420 Loss D.: 0.5765350461006165\n",
            "Epoch: 7420 Loss G.: 0.8572620749473572\n",
            "Epoch: 7430 Loss D.: 0.6010378003120422\n",
            "Epoch: 7430 Loss G.: 0.8605042099952698\n",
            "Epoch: 7440 Loss D.: 0.608521580696106\n",
            "Epoch: 7440 Loss G.: 0.8386169672012329\n",
            "Epoch: 7450 Loss D.: 0.5660461187362671\n",
            "Epoch: 7450 Loss G.: 0.8901485204696655\n",
            "Epoch: 7460 Loss D.: 0.613725483417511\n",
            "Epoch: 7460 Loss G.: 0.9095158576965332\n",
            "Epoch: 7470 Loss D.: 0.5829732418060303\n",
            "Epoch: 7470 Loss G.: 1.0046882629394531\n",
            "Epoch: 7480 Loss D.: 0.6739935874938965\n",
            "Epoch: 7480 Loss G.: 0.925024688243866\n",
            "Epoch: 7490 Loss D.: 0.571631669998169\n",
            "Epoch: 7490 Loss G.: 0.8743969798088074\n",
            "Epoch: 7500 Loss D.: 0.6015310883522034\n",
            "Epoch: 7500 Loss G.: 0.9220774173736572\n",
            "Epoch: 7510 Loss D.: 0.5872606039047241\n",
            "Epoch: 7510 Loss G.: 0.9919158220291138\n",
            "Epoch: 7520 Loss D.: 0.5464266538619995\n",
            "Epoch: 7520 Loss G.: 0.8447512984275818\n",
            "Epoch: 7530 Loss D.: 0.5513306856155396\n",
            "Epoch: 7530 Loss G.: 0.9240077137947083\n",
            "Epoch: 7540 Loss D.: 0.59819096326828\n",
            "Epoch: 7540 Loss G.: 0.9325470328330994\n",
            "Epoch: 7550 Loss D.: 0.5420490503311157\n",
            "Epoch: 7550 Loss G.: 0.8714465498924255\n",
            "Epoch: 7560 Loss D.: 0.5886682868003845\n",
            "Epoch: 7560 Loss G.: 0.8906650543212891\n",
            "Epoch: 7570 Loss D.: 0.5221130847930908\n",
            "Epoch: 7570 Loss G.: 1.050492763519287\n",
            "Epoch: 7580 Loss D.: 0.5954620242118835\n",
            "Epoch: 7580 Loss G.: 0.9694108366966248\n",
            "Epoch: 7590 Loss D.: 0.581583559513092\n",
            "Epoch: 7590 Loss G.: 0.8641306161880493\n",
            "Epoch: 7600 Loss D.: 0.5844857096672058\n",
            "Epoch: 7600 Loss G.: 0.9033229947090149\n",
            "Epoch: 7610 Loss D.: 0.649720311164856\n",
            "Epoch: 7610 Loss G.: 0.888617753982544\n",
            "Epoch: 7620 Loss D.: 0.6231715083122253\n",
            "Epoch: 7620 Loss G.: 0.8506202697753906\n",
            "Epoch: 7630 Loss D.: 0.5364853739738464\n",
            "Epoch: 7630 Loss G.: 0.9068033695220947\n",
            "Epoch: 7640 Loss D.: 0.547709047794342\n",
            "Epoch: 7640 Loss G.: 0.8300951719284058\n",
            "Epoch: 7650 Loss D.: 0.6811474561691284\n",
            "Epoch: 7650 Loss G.: 0.8531349897384644\n",
            "Epoch: 7660 Loss D.: 0.6284661293029785\n",
            "Epoch: 7660 Loss G.: 0.8971903324127197\n",
            "Epoch: 7670 Loss D.: 0.547095000743866\n",
            "Epoch: 7670 Loss G.: 0.9988349080085754\n",
            "Epoch: 7680 Loss D.: 0.5996062755584717\n",
            "Epoch: 7680 Loss G.: 0.8573497533798218\n",
            "Epoch: 7690 Loss D.: 0.5633394718170166\n",
            "Epoch: 7690 Loss G.: 0.8729140162467957\n",
            "Epoch: 7700 Loss D.: 0.6383740305900574\n",
            "Epoch: 7700 Loss G.: 0.941096305847168\n",
            "Epoch: 7710 Loss D.: 0.5879390239715576\n",
            "Epoch: 7710 Loss G.: 0.8701173067092896\n",
            "Epoch: 7720 Loss D.: 0.6806911826133728\n",
            "Epoch: 7720 Loss G.: 0.8235315680503845\n",
            "Epoch: 7730 Loss D.: 0.6185337901115417\n",
            "Epoch: 7730 Loss G.: 0.9231941103935242\n",
            "Epoch: 7740 Loss D.: 0.5972588062286377\n",
            "Epoch: 7740 Loss G.: 0.8801336884498596\n",
            "Epoch: 7750 Loss D.: 0.5509870052337646\n",
            "Epoch: 7750 Loss G.: 1.0527929067611694\n",
            "Epoch: 7760 Loss D.: 0.5959779620170593\n",
            "Epoch: 7760 Loss G.: 0.8952442407608032\n",
            "Epoch: 7770 Loss D.: 0.5680534839630127\n",
            "Epoch: 7770 Loss G.: 0.876779317855835\n",
            "Epoch: 7780 Loss D.: 0.5771724581718445\n",
            "Epoch: 7780 Loss G.: 0.8249944448471069\n",
            "Epoch: 7790 Loss D.: 0.5901306867599487\n",
            "Epoch: 7790 Loss G.: 0.8396584987640381\n",
            "Epoch: 7800 Loss D.: 0.6191783547401428\n",
            "Epoch: 7800 Loss G.: 1.0257291793823242\n",
            "Epoch: 7810 Loss D.: 0.6160112023353577\n",
            "Epoch: 7810 Loss G.: 0.9080951809883118\n",
            "Epoch: 7820 Loss D.: 0.5878565311431885\n",
            "Epoch: 7820 Loss G.: 0.9602820873260498\n",
            "Epoch: 7830 Loss D.: 0.5887939929962158\n",
            "Epoch: 7830 Loss G.: 0.8372199535369873\n",
            "Epoch: 7840 Loss D.: 0.6662857532501221\n",
            "Epoch: 7840 Loss G.: 0.8868336081504822\n",
            "Epoch: 7850 Loss D.: 0.6716976761817932\n",
            "Epoch: 7850 Loss G.: 0.8704141974449158\n",
            "Epoch: 7860 Loss D.: 0.5554444193840027\n",
            "Epoch: 7860 Loss G.: 0.8163930773735046\n",
            "Epoch: 7870 Loss D.: 0.6580978631973267\n",
            "Epoch: 7870 Loss G.: 0.9183465242385864\n",
            "Epoch: 7880 Loss D.: 0.5576006174087524\n",
            "Epoch: 7880 Loss G.: 0.8929196000099182\n",
            "Epoch: 7890 Loss D.: 0.603134274482727\n",
            "Epoch: 7890 Loss G.: 0.8846063613891602\n",
            "Epoch: 7900 Loss D.: 0.5225241184234619\n",
            "Epoch: 7900 Loss G.: 0.9092225432395935\n",
            "Epoch: 7910 Loss D.: 0.5890724658966064\n",
            "Epoch: 7910 Loss G.: 0.8502652645111084\n",
            "Epoch: 7920 Loss D.: 0.5987539887428284\n",
            "Epoch: 7920 Loss G.: 0.8517383337020874\n",
            "Epoch: 7930 Loss D.: 0.5705905556678772\n",
            "Epoch: 7930 Loss G.: 0.9966675043106079\n",
            "Epoch: 7940 Loss D.: 0.6207960247993469\n",
            "Epoch: 7940 Loss G.: 0.8446909189224243\n",
            "Epoch: 7950 Loss D.: 0.7072170376777649\n",
            "Epoch: 7950 Loss G.: 0.8513525724411011\n",
            "Epoch: 7960 Loss D.: 0.6198251247406006\n",
            "Epoch: 7960 Loss G.: 0.8801162242889404\n",
            "Epoch: 7970 Loss D.: 0.5521945953369141\n",
            "Epoch: 7970 Loss G.: 0.9546942710876465\n",
            "Epoch: 7980 Loss D.: 0.5248012542724609\n",
            "Epoch: 7980 Loss G.: 0.9241634607315063\n",
            "Epoch: 7990 Loss D.: 0.5753273963928223\n",
            "Epoch: 7990 Loss G.: 0.875347912311554\n",
            "Epoch: 8000 Loss D.: 0.6422872543334961\n",
            "Epoch: 8000 Loss G.: 0.8516607880592346\n",
            "Epoch: 8010 Loss D.: 0.6086734533309937\n",
            "Epoch: 8010 Loss G.: 0.8625304698944092\n",
            "Epoch: 8020 Loss D.: 0.5991319417953491\n",
            "Epoch: 8020 Loss G.: 0.8784412145614624\n",
            "Epoch: 8030 Loss D.: 0.5922581553459167\n",
            "Epoch: 8030 Loss G.: 0.9350988864898682\n",
            "Epoch: 8040 Loss D.: 0.6026545166969299\n",
            "Epoch: 8040 Loss G.: 0.879896879196167\n",
            "Epoch: 8050 Loss D.: 0.6418029069900513\n",
            "Epoch: 8050 Loss G.: 0.93039870262146\n",
            "Epoch: 8060 Loss D.: 0.6931955814361572\n",
            "Epoch: 8060 Loss G.: 0.8471539616584778\n",
            "Epoch: 8070 Loss D.: 0.6049108505249023\n",
            "Epoch: 8070 Loss G.: 0.8576657176017761\n",
            "Epoch: 8080 Loss D.: 0.595293402671814\n",
            "Epoch: 8080 Loss G.: 0.8530890941619873\n",
            "Epoch: 8090 Loss D.: 0.5377514958381653\n",
            "Epoch: 8090 Loss G.: 0.9319417476654053\n",
            "Epoch: 8100 Loss D.: 0.6423311233520508\n",
            "Epoch: 8100 Loss G.: 0.8015573620796204\n",
            "Epoch: 8110 Loss D.: 0.5599663257598877\n",
            "Epoch: 8110 Loss G.: 0.8534456491470337\n",
            "Epoch: 8120 Loss D.: 0.607065737247467\n",
            "Epoch: 8120 Loss G.: 0.8668838143348694\n",
            "Epoch: 8130 Loss D.: 0.5744526386260986\n",
            "Epoch: 8130 Loss G.: 0.8718940019607544\n",
            "Epoch: 8140 Loss D.: 0.6133645176887512\n",
            "Epoch: 8140 Loss G.: 0.9648655652999878\n",
            "Epoch: 8150 Loss D.: 0.7188557386398315\n",
            "Epoch: 8150 Loss G.: 0.8725220561027527\n",
            "Epoch: 8160 Loss D.: 0.5962314009666443\n",
            "Epoch: 8160 Loss G.: 0.8777424097061157\n",
            "Epoch: 8170 Loss D.: 0.6018159985542297\n",
            "Epoch: 8170 Loss G.: 1.4987618923187256\n",
            "Epoch: 8180 Loss D.: 0.6698212027549744\n",
            "Epoch: 8180 Loss G.: 0.8762567639350891\n",
            "Epoch: 8190 Loss D.: 0.5911365151405334\n",
            "Epoch: 8190 Loss G.: 0.8478084802627563\n",
            "Epoch: 8200 Loss D.: 0.6163279414176941\n",
            "Epoch: 8200 Loss G.: 0.868385910987854\n",
            "Epoch: 8210 Loss D.: 0.6140913963317871\n",
            "Epoch: 8210 Loss G.: 0.8423160314559937\n",
            "Epoch: 8220 Loss D.: 0.5973540544509888\n",
            "Epoch: 8220 Loss G.: 0.883525013923645\n",
            "Epoch: 8230 Loss D.: 0.5982772707939148\n",
            "Epoch: 8230 Loss G.: 0.8290667533874512\n",
            "Epoch: 8240 Loss D.: 0.6398253440856934\n",
            "Epoch: 8240 Loss G.: 0.8725093603134155\n",
            "Epoch: 8250 Loss D.: 0.6107591986656189\n",
            "Epoch: 8250 Loss G.: 0.859607458114624\n",
            "Epoch: 8260 Loss D.: 0.5240916609764099\n",
            "Epoch: 8260 Loss G.: 1.2663854360580444\n",
            "Epoch: 8270 Loss D.: 0.5566348433494568\n",
            "Epoch: 8270 Loss G.: 0.8747460842132568\n",
            "Epoch: 8280 Loss D.: 0.5925314426422119\n",
            "Epoch: 8280 Loss G.: 0.932019054889679\n",
            "Epoch: 8290 Loss D.: 0.5869582891464233\n",
            "Epoch: 8290 Loss G.: 0.9065616130828857\n",
            "Epoch: 8300 Loss D.: 0.6231673359870911\n",
            "Epoch: 8300 Loss G.: 0.8574600219726562\n",
            "Epoch: 8310 Loss D.: 0.5566238760948181\n",
            "Epoch: 8310 Loss G.: 0.8750128149986267\n",
            "Epoch: 8320 Loss D.: 0.598035991191864\n",
            "Epoch: 8320 Loss G.: 1.0201787948608398\n",
            "Epoch: 8330 Loss D.: 0.5814565420150757\n",
            "Epoch: 8330 Loss G.: 0.8866737484931946\n",
            "Epoch: 8340 Loss D.: 0.5587182641029358\n",
            "Epoch: 8340 Loss G.: 0.9289717674255371\n",
            "Epoch: 8350 Loss D.: 0.6349882483482361\n",
            "Epoch: 8350 Loss G.: 0.926396906375885\n",
            "Epoch: 8360 Loss D.: 0.6235765814781189\n",
            "Epoch: 8360 Loss G.: 0.8693898320198059\n",
            "Epoch: 8370 Loss D.: 0.6192378401756287\n",
            "Epoch: 8370 Loss G.: 0.9352073669433594\n",
            "Epoch: 8380 Loss D.: 0.6291948556900024\n",
            "Epoch: 8380 Loss G.: 0.8355043530464172\n",
            "Epoch: 8390 Loss D.: 0.6740444898605347\n",
            "Epoch: 8390 Loss G.: 1.005002498626709\n",
            "Epoch: 8400 Loss D.: 0.5839986205101013\n",
            "Epoch: 8400 Loss G.: 1.056807279586792\n",
            "Epoch: 8410 Loss D.: 0.6083265542984009\n",
            "Epoch: 8410 Loss G.: 0.8445349931716919\n",
            "Epoch: 8420 Loss D.: 0.7436894178390503\n",
            "Epoch: 8420 Loss G.: 0.9626177549362183\n",
            "Epoch: 8430 Loss D.: 0.6330828666687012\n",
            "Epoch: 8430 Loss G.: 0.9270802140235901\n",
            "Epoch: 8440 Loss D.: 0.5725932121276855\n",
            "Epoch: 8440 Loss G.: 0.9092589616775513\n",
            "Epoch: 8450 Loss D.: 0.5888620018959045\n",
            "Epoch: 8450 Loss G.: 0.9216985106468201\n",
            "Epoch: 8460 Loss D.: 0.5410149097442627\n",
            "Epoch: 8460 Loss G.: 0.8651574850082397\n",
            "Epoch: 8470 Loss D.: 0.7061256766319275\n",
            "Epoch: 8470 Loss G.: 0.8658753633499146\n",
            "Epoch: 8480 Loss D.: 0.5519540309906006\n",
            "Epoch: 8480 Loss G.: 0.8344690799713135\n",
            "Epoch: 8490 Loss D.: 0.5923581719398499\n",
            "Epoch: 8490 Loss G.: 0.8412469029426575\n",
            "Epoch: 8500 Loss D.: 0.5848840475082397\n",
            "Epoch: 8500 Loss G.: 0.9223194718360901\n",
            "Epoch: 8510 Loss D.: 0.5925668478012085\n",
            "Epoch: 8510 Loss G.: 0.8810139298439026\n",
            "Epoch: 8520 Loss D.: 0.5879786014556885\n",
            "Epoch: 8520 Loss G.: 0.9398545622825623\n",
            "Epoch: 8530 Loss D.: 0.5757042765617371\n",
            "Epoch: 8530 Loss G.: 0.9201135635375977\n",
            "Epoch: 8540 Loss D.: 0.5316528677940369\n",
            "Epoch: 8540 Loss G.: 0.8886091113090515\n",
            "Epoch: 8550 Loss D.: 0.5639504194259644\n",
            "Epoch: 8550 Loss G.: 0.9720410704612732\n",
            "Epoch: 8560 Loss D.: 0.6103209257125854\n",
            "Epoch: 8560 Loss G.: 0.870272696018219\n",
            "Epoch: 8570 Loss D.: 0.5027162432670593\n",
            "Epoch: 8570 Loss G.: 0.9347422122955322\n",
            "Epoch: 8580 Loss D.: 0.5786965489387512\n",
            "Epoch: 8580 Loss G.: 0.9931040406227112\n",
            "Epoch: 8590 Loss D.: 0.6415053606033325\n",
            "Epoch: 8590 Loss G.: 0.9317036867141724\n",
            "Epoch: 8600 Loss D.: 0.6421010494232178\n",
            "Epoch: 8600 Loss G.: 1.0097702741622925\n",
            "Epoch: 8610 Loss D.: 0.6169092059135437\n",
            "Epoch: 8610 Loss G.: 0.9245584011077881\n",
            "Epoch: 8620 Loss D.: 0.5575204491615295\n",
            "Epoch: 8620 Loss G.: 0.8606951236724854\n",
            "Epoch: 8630 Loss D.: 0.6226868629455566\n",
            "Epoch: 8630 Loss G.: 1.0570935010910034\n",
            "Epoch: 8640 Loss D.: 0.6021246910095215\n",
            "Epoch: 8640 Loss G.: 0.8262421488761902\n",
            "Epoch: 8650 Loss D.: 0.6151282787322998\n",
            "Epoch: 8650 Loss G.: 0.8466957807540894\n",
            "Epoch: 8660 Loss D.: 0.5817739963531494\n",
            "Epoch: 8660 Loss G.: 0.9015061855316162\n",
            "Epoch: 8670 Loss D.: 0.5488106608390808\n",
            "Epoch: 8670 Loss G.: 0.9024006128311157\n",
            "Epoch: 8680 Loss D.: 0.5615272521972656\n",
            "Epoch: 8680 Loss G.: 0.8907871246337891\n",
            "Epoch: 8690 Loss D.: 0.6459726691246033\n",
            "Epoch: 8690 Loss G.: 0.8991192579269409\n",
            "Epoch: 8700 Loss D.: 0.552291989326477\n",
            "Epoch: 8700 Loss G.: 0.8177679181098938\n",
            "Epoch: 8710 Loss D.: 0.6497213840484619\n",
            "Epoch: 8710 Loss G.: 0.9144747257232666\n",
            "Epoch: 8720 Loss D.: 0.573073148727417\n",
            "Epoch: 8720 Loss G.: 0.8599236011505127\n",
            "Epoch: 8730 Loss D.: 0.5838607549667358\n",
            "Epoch: 8730 Loss G.: 0.8855388760566711\n",
            "Epoch: 8740 Loss D.: 0.6001801490783691\n",
            "Epoch: 8740 Loss G.: 0.8771626949310303\n",
            "Epoch: 8750 Loss D.: 0.5989578366279602\n",
            "Epoch: 8750 Loss G.: 0.8708012700080872\n",
            "Epoch: 8760 Loss D.: 0.5604242086410522\n",
            "Epoch: 8760 Loss G.: 1.0419257879257202\n",
            "Epoch: 8770 Loss D.: 0.6308935284614563\n",
            "Epoch: 8770 Loss G.: 0.878343403339386\n",
            "Epoch: 8780 Loss D.: 0.6391586661338806\n",
            "Epoch: 8780 Loss G.: 0.8829466700553894\n",
            "Epoch: 8790 Loss D.: 0.6153019070625305\n",
            "Epoch: 8790 Loss G.: 0.873862087726593\n",
            "Epoch: 8800 Loss D.: 0.6145159602165222\n",
            "Epoch: 8800 Loss G.: 0.8879294395446777\n",
            "Epoch: 8810 Loss D.: 0.518557071685791\n",
            "Epoch: 8810 Loss G.: 0.8989583253860474\n",
            "Epoch: 8820 Loss D.: 0.5416355729103088\n",
            "Epoch: 8820 Loss G.: 0.956927478313446\n",
            "Epoch: 8830 Loss D.: 0.5908458232879639\n",
            "Epoch: 8830 Loss G.: 0.826966404914856\n",
            "Epoch: 8840 Loss D.: 0.6215754151344299\n",
            "Epoch: 8840 Loss G.: 1.1415324211120605\n",
            "Epoch: 8850 Loss D.: 0.5768129825592041\n",
            "Epoch: 8850 Loss G.: 0.9113373160362244\n",
            "Epoch: 8860 Loss D.: 0.6341356635093689\n",
            "Epoch: 8860 Loss G.: 0.9884908199310303\n",
            "Epoch: 8870 Loss D.: 0.5506528615951538\n",
            "Epoch: 8870 Loss G.: 0.9201322197914124\n",
            "Epoch: 8880 Loss D.: 0.5602600574493408\n",
            "Epoch: 8880 Loss G.: 0.8677957057952881\n",
            "Epoch: 8890 Loss D.: 0.5346277952194214\n",
            "Epoch: 8890 Loss G.: 0.8324974179267883\n",
            "Epoch: 8900 Loss D.: 0.5776359438896179\n",
            "Epoch: 8900 Loss G.: 0.9813563823699951\n",
            "Epoch: 8910 Loss D.: 0.633886456489563\n",
            "Epoch: 8910 Loss G.: 1.020997166633606\n",
            "Epoch: 8920 Loss D.: 0.5715804100036621\n",
            "Epoch: 8920 Loss G.: 0.9593093395233154\n",
            "Epoch: 8930 Loss D.: 0.5879417061805725\n",
            "Epoch: 8930 Loss G.: 0.9276595711708069\n",
            "Epoch: 8940 Loss D.: 0.5701757669448853\n",
            "Epoch: 8940 Loss G.: 0.9543091654777527\n",
            "Epoch: 8950 Loss D.: 0.5884206891059875\n",
            "Epoch: 8950 Loss G.: 0.9009223580360413\n",
            "Epoch: 8960 Loss D.: 0.602013885974884\n",
            "Epoch: 8960 Loss G.: 0.9116196632385254\n",
            "Epoch: 8970 Loss D.: 0.5917857885360718\n",
            "Epoch: 8970 Loss G.: 0.8922293782234192\n",
            "Epoch: 8980 Loss D.: 0.6173372268676758\n",
            "Epoch: 8980 Loss G.: 0.885204017162323\n",
            "Epoch: 8990 Loss D.: 0.5901299715042114\n",
            "Epoch: 8990 Loss G.: 0.8725857734680176\n",
            "Epoch: 9000 Loss D.: 0.5392552018165588\n",
            "Epoch: 9000 Loss G.: 0.8964264392852783\n",
            "Epoch: 9010 Loss D.: 0.5636342763900757\n",
            "Epoch: 9010 Loss G.: 0.8807360529899597\n",
            "Epoch: 9020 Loss D.: 0.5824686288833618\n",
            "Epoch: 9020 Loss G.: 0.8303770422935486\n",
            "Epoch: 9030 Loss D.: 0.5457223653793335\n",
            "Epoch: 9030 Loss G.: 0.8487580418586731\n",
            "Epoch: 9040 Loss D.: 0.5774779319763184\n",
            "Epoch: 9040 Loss G.: 0.9090876579284668\n",
            "Epoch: 9050 Loss D.: 0.6486271619796753\n",
            "Epoch: 9050 Loss G.: 1.0195646286010742\n",
            "Epoch: 9060 Loss D.: 0.5936639308929443\n",
            "Epoch: 9060 Loss G.: 1.0652906894683838\n",
            "Epoch: 9070 Loss D.: 0.6670257449150085\n",
            "Epoch: 9070 Loss G.: 0.8664538860321045\n",
            "Epoch: 9080 Loss D.: 0.5761445760726929\n",
            "Epoch: 9080 Loss G.: 1.0454895496368408\n",
            "Epoch: 9090 Loss D.: 0.6083230376243591\n",
            "Epoch: 9090 Loss G.: 0.8662683367729187\n",
            "Epoch: 9100 Loss D.: 0.5578027367591858\n",
            "Epoch: 9100 Loss G.: 0.8494117259979248\n",
            "Epoch: 9110 Loss D.: 0.589768648147583\n",
            "Epoch: 9110 Loss G.: 0.8627979159355164\n",
            "Epoch: 9120 Loss D.: 0.5411428809165955\n",
            "Epoch: 9120 Loss G.: 0.8775684833526611\n",
            "Epoch: 9130 Loss D.: 0.6002775430679321\n",
            "Epoch: 9130 Loss G.: 0.820826530456543\n",
            "Epoch: 9140 Loss D.: 0.5437486171722412\n",
            "Epoch: 9140 Loss G.: 0.8728574514389038\n",
            "Epoch: 9150 Loss D.: 0.6156617999076843\n",
            "Epoch: 9150 Loss G.: 0.8897106051445007\n",
            "Epoch: 9160 Loss D.: 0.5696998834609985\n",
            "Epoch: 9160 Loss G.: 0.8416064977645874\n",
            "Epoch: 9170 Loss D.: 0.601168155670166\n",
            "Epoch: 9170 Loss G.: 0.854350745677948\n",
            "Epoch: 9180 Loss D.: 0.5802829265594482\n",
            "Epoch: 9180 Loss G.: 0.8641836643218994\n",
            "Epoch: 9190 Loss D.: 0.5554999709129333\n",
            "Epoch: 9190 Loss G.: 0.9192451238632202\n",
            "Epoch: 9200 Loss D.: 0.6179490089416504\n",
            "Epoch: 9200 Loss G.: 0.8638859987258911\n",
            "Epoch: 9210 Loss D.: 0.5787197947502136\n",
            "Epoch: 9210 Loss G.: 0.8986556529998779\n",
            "Epoch: 9220 Loss D.: 0.5591073632240295\n",
            "Epoch: 9220 Loss G.: 0.8435937166213989\n",
            "Epoch: 9230 Loss D.: 0.49138984084129333\n",
            "Epoch: 9230 Loss G.: 0.9491564631462097\n",
            "Epoch: 9240 Loss D.: 0.5555112361907959\n",
            "Epoch: 9240 Loss G.: 0.934870719909668\n",
            "Epoch: 9250 Loss D.: 0.580375075340271\n",
            "Epoch: 9250 Loss G.: 0.9037184119224548\n",
            "Epoch: 9260 Loss D.: 0.5976163148880005\n",
            "Epoch: 9260 Loss G.: 0.9279629588127136\n",
            "Epoch: 9270 Loss D.: 0.6057112216949463\n",
            "Epoch: 9270 Loss G.: 0.9002618193626404\n",
            "Epoch: 9280 Loss D.: 0.6009856462478638\n",
            "Epoch: 9280 Loss G.: 0.8842760324478149\n",
            "Epoch: 9290 Loss D.: 0.5851761102676392\n",
            "Epoch: 9290 Loss G.: 0.8970683813095093\n",
            "Epoch: 9300 Loss D.: 0.5025904774665833\n",
            "Epoch: 9300 Loss G.: 0.956346333026886\n",
            "Epoch: 9310 Loss D.: 0.5088027119636536\n",
            "Epoch: 9310 Loss G.: 0.9448262453079224\n",
            "Epoch: 9320 Loss D.: 0.6048359870910645\n",
            "Epoch: 9320 Loss G.: 0.834659218788147\n",
            "Epoch: 9330 Loss D.: 0.5938735008239746\n",
            "Epoch: 9330 Loss G.: 0.8856011629104614\n",
            "Epoch: 9340 Loss D.: 0.5023154616355896\n",
            "Epoch: 9340 Loss G.: 0.8357506990432739\n",
            "Epoch: 9350 Loss D.: 0.599216639995575\n",
            "Epoch: 9350 Loss G.: 0.8732956647872925\n",
            "Epoch: 9360 Loss D.: 0.5474750995635986\n",
            "Epoch: 9360 Loss G.: 0.8929297924041748\n",
            "Epoch: 9370 Loss D.: 0.6199512481689453\n",
            "Epoch: 9370 Loss G.: 1.0149105787277222\n",
            "Epoch: 9380 Loss D.: 0.6016114354133606\n",
            "Epoch: 9380 Loss G.: 0.891225278377533\n",
            "Epoch: 9390 Loss D.: 0.5842626690864563\n",
            "Epoch: 9390 Loss G.: 0.9466468691825867\n",
            "Epoch: 9400 Loss D.: 0.5686606168746948\n",
            "Epoch: 9400 Loss G.: 1.2575839757919312\n",
            "Epoch: 9410 Loss D.: 0.5761110782623291\n",
            "Epoch: 9410 Loss G.: 0.8999547958374023\n",
            "Epoch: 9420 Loss D.: 0.5569761395454407\n",
            "Epoch: 9420 Loss G.: 0.8618396520614624\n",
            "Epoch: 9430 Loss D.: 0.5603240728378296\n",
            "Epoch: 9430 Loss G.: 0.861083447933197\n",
            "Epoch: 9440 Loss D.: 0.5774504542350769\n",
            "Epoch: 9440 Loss G.: 0.9530007839202881\n",
            "Epoch: 9450 Loss D.: 0.5319260358810425\n",
            "Epoch: 9450 Loss G.: 0.9268335103988647\n",
            "Epoch: 9460 Loss D.: 0.5242799520492554\n",
            "Epoch: 9460 Loss G.: 0.9076282978057861\n",
            "Epoch: 9470 Loss D.: 0.5678110718727112\n",
            "Epoch: 9470 Loss G.: 0.9232825636863708\n",
            "Epoch: 9480 Loss D.: 0.5287349820137024\n",
            "Epoch: 9480 Loss G.: 0.8601012825965881\n",
            "Epoch: 9490 Loss D.: 0.618335485458374\n",
            "Epoch: 9490 Loss G.: 0.8626856207847595\n",
            "Epoch: 9500 Loss D.: 0.5574120879173279\n",
            "Epoch: 9500 Loss G.: 0.872717022895813\n",
            "Epoch: 9510 Loss D.: 0.5154417753219604\n",
            "Epoch: 9510 Loss G.: 0.8655965328216553\n",
            "Epoch: 9520 Loss D.: 0.5647333264350891\n",
            "Epoch: 9520 Loss G.: 0.852586030960083\n",
            "Epoch: 9530 Loss D.: 0.6971768140792847\n",
            "Epoch: 9530 Loss G.: 0.8956678509712219\n",
            "Epoch: 9540 Loss D.: 0.6271407604217529\n",
            "Epoch: 9540 Loss G.: 0.9248532652854919\n",
            "Epoch: 9550 Loss D.: 0.6038609743118286\n",
            "Epoch: 9550 Loss G.: 0.883129894733429\n",
            "Epoch: 9560 Loss D.: 0.5675829648971558\n",
            "Epoch: 9560 Loss G.: 0.8807722330093384\n",
            "Epoch: 9570 Loss D.: 0.5660554766654968\n",
            "Epoch: 9570 Loss G.: 0.8509752750396729\n",
            "Epoch: 9580 Loss D.: 0.6090541481971741\n",
            "Epoch: 9580 Loss G.: 0.8530399799346924\n",
            "Epoch: 9590 Loss D.: 0.5811250805854797\n",
            "Epoch: 9590 Loss G.: 1.1731679439544678\n",
            "Epoch: 9600 Loss D.: 0.5653430223464966\n",
            "Epoch: 9600 Loss G.: 1.0605244636535645\n",
            "Epoch: 9610 Loss D.: 0.8203421831130981\n",
            "Epoch: 9610 Loss G.: 1.1496832370758057\n",
            "Epoch: 9620 Loss D.: 0.6396422386169434\n",
            "Epoch: 9620 Loss G.: 0.9959590435028076\n",
            "Epoch: 9630 Loss D.: 0.5564001798629761\n",
            "Epoch: 9630 Loss G.: 0.8249713182449341\n",
            "Epoch: 9640 Loss D.: 0.5725569725036621\n",
            "Epoch: 9640 Loss G.: 0.9463444948196411\n",
            "Epoch: 9650 Loss D.: 0.4864369034767151\n",
            "Epoch: 9650 Loss G.: 0.9409669637680054\n",
            "Epoch: 9660 Loss D.: 0.6302862763404846\n",
            "Epoch: 9660 Loss G.: 1.035923719406128\n",
            "Epoch: 9670 Loss D.: 0.5770108699798584\n",
            "Epoch: 9670 Loss G.: 1.2077000141143799\n",
            "Epoch: 9680 Loss D.: 0.5712613463401794\n",
            "Epoch: 9680 Loss G.: 0.9467900395393372\n",
            "Epoch: 9690 Loss D.: 0.6060603260993958\n",
            "Epoch: 9690 Loss G.: 0.8772064447402954\n",
            "Epoch: 9700 Loss D.: 0.6060609817504883\n",
            "Epoch: 9700 Loss G.: 0.8905973434448242\n",
            "Epoch: 9710 Loss D.: 0.5809647440910339\n",
            "Epoch: 9710 Loss G.: 0.9167484641075134\n",
            "Epoch: 9720 Loss D.: 0.5359093546867371\n",
            "Epoch: 9720 Loss G.: 0.930885374546051\n",
            "Epoch: 9730 Loss D.: 0.5727110505104065\n",
            "Epoch: 9730 Loss G.: 0.8971722722053528\n",
            "Epoch: 9740 Loss D.: 0.5265603065490723\n",
            "Epoch: 9740 Loss G.: 0.9695383906364441\n",
            "Epoch: 9750 Loss D.: 0.5858378410339355\n",
            "Epoch: 9750 Loss G.: 0.9895692467689514\n",
            "Epoch: 9760 Loss D.: 0.47321516275405884\n",
            "Epoch: 9760 Loss G.: 0.8906756639480591\n",
            "Epoch: 9770 Loss D.: 0.4805466830730438\n",
            "Epoch: 9770 Loss G.: 0.8584002256393433\n",
            "Epoch: 9780 Loss D.: 0.5909503698348999\n",
            "Epoch: 9780 Loss G.: 0.9009360074996948\n",
            "Epoch: 9790 Loss D.: 0.5589770674705505\n",
            "Epoch: 9790 Loss G.: 0.8828877806663513\n",
            "Epoch: 9800 Loss D.: 0.6260383129119873\n",
            "Epoch: 9800 Loss G.: 0.9099809527397156\n",
            "Epoch: 9810 Loss D.: 0.5578192472457886\n",
            "Epoch: 9810 Loss G.: 0.8636416792869568\n",
            "Epoch: 9820 Loss D.: 0.5264355540275574\n",
            "Epoch: 9820 Loss G.: 0.8893857002258301\n",
            "Epoch: 9830 Loss D.: 0.6567347049713135\n",
            "Epoch: 9830 Loss G.: 1.040197491645813\n",
            "Epoch: 9840 Loss D.: 0.5706861019134521\n",
            "Epoch: 9840 Loss G.: 0.9758471846580505\n",
            "Epoch: 9850 Loss D.: 0.695270299911499\n",
            "Epoch: 9850 Loss G.: 0.8578181266784668\n",
            "Epoch: 9860 Loss D.: 0.5415199398994446\n",
            "Epoch: 9860 Loss G.: 0.8453542590141296\n",
            "Epoch: 9870 Loss D.: 0.530551016330719\n",
            "Epoch: 9870 Loss G.: 1.0223147869110107\n",
            "Epoch: 9880 Loss D.: 0.6132391095161438\n",
            "Epoch: 9880 Loss G.: 0.9101065397262573\n",
            "Epoch: 9890 Loss D.: 0.5955827236175537\n",
            "Epoch: 9890 Loss G.: 0.8400397300720215\n",
            "Epoch: 9900 Loss D.: 0.6111884117126465\n",
            "Epoch: 9900 Loss G.: 0.9124637246131897\n",
            "Epoch: 9910 Loss D.: 0.5640034079551697\n",
            "Epoch: 9910 Loss G.: 0.8788583874702454\n",
            "Epoch: 9920 Loss D.: 0.5891698598861694\n",
            "Epoch: 9920 Loss G.: 0.902432918548584\n",
            "Epoch: 9930 Loss D.: 0.5871610641479492\n",
            "Epoch: 9930 Loss G.: 1.0066564083099365\n",
            "Epoch: 9940 Loss D.: 0.6062496900558472\n",
            "Epoch: 9940 Loss G.: 0.8651770353317261\n",
            "Epoch: 9950 Loss D.: 0.6284614205360413\n",
            "Epoch: 9950 Loss G.: 0.8801457285881042\n",
            "Epoch: 9960 Loss D.: 0.6009247303009033\n",
            "Epoch: 9960 Loss G.: 0.8986836671829224\n",
            "Epoch: 9970 Loss D.: 0.668511688709259\n",
            "Epoch: 9970 Loss G.: 0.9300426840782166\n",
            "Epoch: 9980 Loss D.: 0.5503383278846741\n",
            "Epoch: 9980 Loss G.: 0.8754597306251526\n",
            "Epoch: 9990 Loss D.: 0.5416650176048279\n",
            "Epoch: 9990 Loss G.: 0.8989048004150391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking the Samples Generated by the GAN\n",
        "Generative adversarial networks are designed to generate data. So, after the training process is finished, you can get some random samples from the latent space and feed them to the generator to obtain some generated samples:"
      ],
      "metadata": {
        "id": "weqsOst-p4iY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_space_samples = torch.randn(14, 3)\n",
        "generated_samples = generator(latent_space_samples)"
      ],
      "metadata": {
        "id": "2LPETPYgp3tS"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_samples"
      ],
      "metadata": {
        "id": "Ow0HQVyek1a-",
        "outputId": "624dc3d4-0266-4a54-813b-96fcf7e35897",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 8.6923e-02,  8.2833e-02, -4.3210e-03],\n",
              "        [ 7.6002e-01,  8.0047e-02, -5.5947e-03],\n",
              "        [ 7.3000e-02,  8.2744e-02, -4.3105e-03],\n",
              "        [ 2.1403e+02,  5.9599e-01,  1.8860e-01],\n",
              "        [ 5.5016e+02,  2.2629e+00,  7.9087e-01],\n",
              "        [ 7.2237e-02,  8.2727e-02, -4.3067e-03],\n",
              "        [ 9.3325e-01,  7.9236e-02, -5.9304e-03],\n",
              "        [ 7.7388e-02,  8.2837e-02, -4.3328e-03],\n",
              "        [ 7.2213e-02,  8.2727e-02, -4.3065e-03],\n",
              "        [ 1.4116e+01,  7.0683e-02, -2.5284e-02],\n",
              "        [ 6.0098e+01,  1.0631e-02, -8.7073e-03],\n",
              "        [ 4.2329e-01,  8.1206e-02, -4.9535e-03],\n",
              "        [ 1.1145e+00,  7.8681e-02, -6.2234e-03],\n",
              "        [ 1.0501e+03,  4.6273e+00,  1.6495e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_samples = generated_samples.detach()\n",
        "plt.plot(generated_samples[:, 0], generated_samples[:, 1], \".\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "8lXjD9ogqNxr",
        "outputId": "f4bde99f-349e-4749-bec1-08490cc11011"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f40720c1510>]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(generated_samples[:, 0], generated_samples[:, 2], \".\")"
      ],
      "metadata": {
        "id": "mPXCmCaKbwqT",
        "outputId": "e81eb734-7122-4c99-f200-c8745bd9e800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4072036190>]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(generated_samples[:, 1], generated_samples[:, 2], \"-o\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "qWxYHcd5j-lf",
        "outputId": "d28e4ead-16d6-4815-fdc9-e831dca8fea3"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4071fa9610>]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}